#!/usr/bin/env python3
"""
10remove_isolated_name_lists.py - åˆªé™¤å­¤ç«‹çš„äººååˆ—è¡¨

å•é¡Œï¼š
AI ç”Ÿæˆçš„å ±å‘Šä¸­ï¼Œæ¯å€‹ä¸»é¡Œé–‹é ­éƒ½æœƒå‡ºç¾ä¸€æ®µç„¡æ„ç¾©çš„äººååˆ—è¡¨ï¼š
```
## 2. å°ˆæ¡ˆ / æ¡ˆä»¶é€²åº¦èˆ‡è¿½è¹¤

*   è”¡å®—å“²
*   æ—ä»¥å‡¡
*   Brenda Tsai
*   Chris Ho
*   Vandose Chen

*   **å ±å‘Šåˆ†äº«:**
    ...
```

é€™äº›å­¤ç«‹çš„äººååˆ—è¡¨æ²’æœ‰ä»»ä½•èªªæ˜ï¼Œæ‡‰è©²åˆªé™¤ã€‚

ç‰¹å¾µï¼š
1. ç·Šæ¥åœ¨ ## æ¨™é¡Œä¹‹å¾Œï¼ˆå¯èƒ½æœ‰ç©ºè¡Œï¼‰
2. åªæœ‰äººåï¼Œæ²’æœ‰å†’è™Ÿã€èªªæ˜ã€å­å½ˆé»å…§å®¹
3. åˆ—è¡¨å¾Œæœ‰ç©ºè¡Œï¼Œç„¶å¾Œæ‰æ˜¯çœŸæ­£çš„å…§å®¹

ç”¨æ³•ï¼š
python 10remove_isolated_name_lists.py --input report.md --output report_clean.md
"""

import argparse
import re
from pathlib import Path


def is_isolated_name_line(line: str) -> bool:
    """åˆ¤æ–·æ˜¯å¦æ˜¯å­¤ç«‹çš„äººååˆ—è¡¨é …"""
    stripped = line.strip()

    # å¿…é ˆæ˜¯åˆ—è¡¨é …
    if not stripped.startswith('*'):
        return False

    # ç§»é™¤åˆ—è¡¨ç¬¦è™Ÿ
    content = stripped.lstrip('*').strip()

    # ç©ºçš„åˆ—è¡¨é …
    if not content:
        return False

    # æœ‰å†’è™Ÿæˆ–èªªæ˜æ–‡å­—ï¼ˆåœ¨å†’è™Ÿå¾Œæœ‰å…§å®¹ï¼‰ï¼Œä¸æ˜¯å­¤ç«‹äººå
    if ':' in content or 'ï¼š' in content:
        # ä½†å¦‚æœå†’è™Ÿå¾Œé¢æ˜¯ç©ºçš„ï¼ˆå¦‚ã€Œ**åƒèˆ‡è€…ï¼š**ã€ï¼‰ï¼Œé€™ä¸ç®—
        colon_idx = max(content.find(':'), content.find('ï¼š'))
        if colon_idx > 0 and colon_idx < len(content) - 1:
            after_colon = content[colon_idx+1:].strip()
            if after_colon and not after_colon.startswith('*'):
                return False

    # æœ‰å­åˆ—è¡¨ï¼ˆåµŒå¥—çš„ *ï¼‰ï¼Œä¸æ˜¯å­¤ç«‹äººå
    if content.count('*') > 2:  # å…è¨± **XX** æ ¼å¼
        return False

    # æª¢æŸ¥æ˜¯å¦åƒäººå
    # ç‰¹å¾µï¼š
    # - åŒ…å«ä¸­æ–‡æˆ–è‹±æ–‡åå­—
    # - å¯èƒ½æœ‰æ‹¬è™Ÿï¼ˆè‹±æ–‡åï¼‰
    # - é•·åº¦ä¸æœƒå¤ªé•·ï¼ˆäººåé€šå¸¸ < 30 å­—ï¼‰
    # - æ²’æœ‰æ˜é¡¯çš„å‹•è©ã€æ•¸å­—ã€å–®ä½

    if len(content) > 30:
        return False

    # åŒ…å«æ˜é¡¯çš„å ±å‘Šå…§å®¹é—œéµè©ï¼Œä¸æ˜¯äººå
    report_keywords = [
        'å ±å‘Š', 'ç¢ºèª', 'è¿½è¹¤', 'è² è²¬', 'å®Œæˆ', 'é€²åº¦',
        'é‡‘é¡', 'è¬', 'å„„', 'å…ƒ', 'æœˆ', 'æ—¥',
        'å·²', 'å°‡', 'éœ€', 'æ‡‰', 'å¯', 'æœƒ', 'è¦', 'èƒ½',
        'æ¡ˆ', 'å°ˆæ¡ˆ', 'åˆç´„', 'è¨‚å–®', 'ç™¼ç¥¨'
    ]
    for keyword in report_keywords:
        if keyword in content:
            return False

    # ç¬¦åˆäººåæ¨¡å¼
    # ä¸­æ–‡å æˆ– è‹±æ–‡å æˆ– ä¸­è‹±æ–‡æ··åˆ
    name_pattern = r'^[\u4e00-\u9fff\sA-Za-z()ï¼ˆï¼‰]+$'
    if re.match(name_pattern, content):
        return True

    return False


def remove_isolated_name_lists(content: str) -> str:
    """åˆªé™¤å­¤ç«‹çš„äººååˆ—è¡¨"""
    lines = content.split('\n')
    result = []

    i = 0
    while i < len(lines):
        line = lines[i]

        # æª¢æ¸¬æ˜¯å¦é€²å…¥ä¸»é¡Œæ¨™é¡Œ
        if re.match(r'^##\s+\d+\.', line.strip()):
            result.append(line)
            i += 1

            # è·³éæ¨™é¡Œå¾Œçš„ç©ºè¡Œ
            while i < len(lines) and lines[i].strip() == '':
                result.append(lines[i])
                i += 1

            # æª¢æŸ¥æ˜¯å¦æ˜¯å­¤ç«‹äººååˆ—è¡¨
            name_list_start = i
            name_count = 0

            while i < len(lines):
                current_line = lines[i]

                # ç©ºè¡Œï¼Œå¯èƒ½æ˜¯åˆ—è¡¨çµæŸ
                if current_line.strip() == '':
                    i += 1
                    continue

                # æ˜¯å­¤ç«‹äººå
                if is_isolated_name_line(current_line):
                    name_count += 1
                    i += 1
                else:
                    # ä¸æ˜¯äººåï¼Œåˆ—è¡¨çµæŸ
                    break

            # å¦‚æœæ‰¾åˆ°å­¤ç«‹äººååˆ—è¡¨ï¼ˆè‡³å°‘3å€‹äººåï¼‰ï¼Œè·³éå®ƒå€‘
            if name_count >= 3:
                print(f"  ğŸ—‘ï¸  åˆªé™¤å­¤ç«‹äººååˆ—è¡¨ï¼ˆ{name_count} å€‹äººåï¼‰", flush=True)
                # i å·²ç¶“æŒ‡å‘éäººåè¡Œï¼Œç¹¼çºŒè™•ç†
                continue
            else:
                # ä¸æ˜¯å­¤ç«‹åˆ—è¡¨ï¼Œæ¢å¾©è™•ç†
                i = name_list_start
                continue

        result.append(line)
        i += 1

    return '\n'.join(result)


def main():
    parser = argparse.ArgumentParser(
        description='åˆªé™¤å ±å‘Šä¸­å­¤ç«‹çš„äººååˆ—è¡¨'
    )

    parser.add_argument('--input', required=True, help='è¼¸å…¥ MD æ–‡ä»¶')
    parser.add_argument('--output', help='è¼¸å‡ºæ–‡ä»¶ï¼ˆé»˜èªï¼šinput_no_name_lists.mdï¼‰')

    args = parser.parse_args()

    input_file = Path(args.input)
    if not input_file.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼š{input_file}")
        return

    # è®€å–
    with open(input_file, 'r', encoding='utf-8') as f:
        content = f.read()

    print("=" * 60)
    print("ğŸ§¹ åˆªé™¤å­¤ç«‹äººååˆ—è¡¨")
    print("=" * 60)

    # è™•ç†
    cleaned = remove_isolated_name_lists(content)

    # è¼¸å‡ºè·¯å¾‘
    if args.output:
        output_file = Path(args.output)
    else:
        output_file = input_file.parent / f"{input_file.stem}_no_name_lists.md"

    # ä¿å­˜
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(cleaned)

    # çµ±è¨ˆ
    original_lines = len(content.split('\n'))
    cleaned_lines = len(cleaned.split('\n'))
    removed_lines = original_lines - cleaned_lines

    print(f"\nâœ… å®Œæˆï¼")
    print(f"  - åŸå§‹è¡Œæ•¸ï¼š{original_lines}")
    print(f"  - æ¸…ç†å¾Œï¼š{cleaned_lines}")
    print(f"  - åˆªé™¤ï¼š{removed_lines} è¡Œ")
    print(f"\nğŸ’¾ å·²å„²å­˜ï¼š{output_file}")
    print("=" * 60)


if __name__ == '__main__':
    main()
