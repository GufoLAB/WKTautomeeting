#!/usr/bin/env python3
"""
8merge_clean_topics.py - å¿«é€Ÿä¿®å¤å¹¶åˆå¹¶ä¸»é¢˜åˆ†ç±»æŠ¥å‘Š

åŠŸèƒ½ï¼š
1. ä»æ‰€æœ‰ä¸»é¢˜ MD ä¸­æå–ç»Ÿä¸€çš„ä¼šè®®å…ƒæ•°æ®
2. æ¸…ç†å„ä¸»é¢˜çš„æ ¼å¼é—®é¢˜ï¼ˆé‡å¤æ ‡é¢˜ã€å ä½ç¬¦ç­‰ï¼‰
3. ç”Ÿæˆæ¼‚äº®çš„ç»Ÿä¸€å¼€å¤´
4. æŒ‰æ’åºåˆå¹¶æˆå•ä¸€æŠ¥å‘Š

ç‰¹ç‚¹ï¼š
- ä¸éœ€è¦ AIï¼ˆ5ç§’å®Œæˆï¼‰
- ä¸ä¿®æ”¹åŸå§‹æ–‡ä»¶
- ç”Ÿæˆå¹²å‡€çš„ä¸»é¢˜åˆ†ç±»æŠ¥å‘Š

ç”¨æ³•ï¼š
python 8merge_clean_topics.py --input-dir /path/to/md/files --output topic_report.md
æˆ–
python 8merge_clean_topics.py --from-judgment /path/to/topic_judgments.json --output topic_report.md
"""

import argparse
import os
import re
import json
from pathlib import Path
from collections import Counter
from typing import List, Dict


# ==================== å…ƒæ•°æ®æå– ====================

def extract_metadata_from_files(md_files: List[Path]) -> Dict:
    """ä»æ‰€æœ‰ MD æ–‡ä»¶ä¸­æå–å¹¶ç»Ÿä¸€ä¼šè®®å…ƒæ•°æ®"""

    dates = []
    times = []
    locations = []
    durations = []
    attendees = set()
    meeting_names = []

    for md_file in md_files:
        with open(md_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå–æ—¥æœŸ
        date_patterns = [
            r'æ—¥æœŸ[ï¼š:]\s*(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
            r'æ—¥æœŸ[ï¼š:]\s*(\d{4}/\d{1,2}/\d{1,2})',
            r'(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
        ]
        for pattern in date_patterns:
            matches = re.findall(pattern, content)
            dates.extend(matches)

        # æå–æ—¶é—´
        time_match = re.search(r'æ™‚é–“[ï¼š:]\s*([^\n]+)', content)
        if time_match:
            times.append(time_match.group(1))

        # æå–åœ°ç‚¹
        location_patterns = [
            r'åœ°é»[ï¼š:]\s*([^\n]+)',
            r'å½¢å¼[ï¼š:]\s*([^\n]+)',
        ]
        for pattern in location_patterns:
            matches = re.findall(pattern, content)
            locations.extend(matches)

        # æå–æ—¶é•¿
        duration_patterns = [
            r'æ™‚é•·[ï¼š:]\s*([^\n]+)',
            r'éŒ„è£½æ™‚é–“[ï¼š:]\s*([^\n]+)',
            r'(\d+\s*åˆ†\s*\d+\s*ç§’)',
        ]
        for pattern in duration_patterns:
            matches = re.findall(pattern, content)
            durations.extend(matches)

        # æå–ä¸ä¼šè€…ï¼ˆä¸­è‹±æ–‡å§“åï¼‰
        # ä¸­æ–‡å§“å 2-4å­—
        cn_names = re.findall(r'[\u4e00-\u9fa5]{2,4}\s*\([A-Za-z\s]+\)', content)
        attendees.update(cn_names)

        # è‹±æ–‡å§“å
        en_names = re.findall(r'[A-Z][a-z]+\s+[A-Z][a-z]+(?:\s+\([^)]+\))?', content)
        attendees.update(en_names)

        # æå–ä¼šè®®åç§°
        name_match = re.search(r'æœƒè­°åç¨±[ï¼š:]\s*([^\n]+)', content)
        if name_match:
            meeting_names.append(name_match.group(1).strip())

    # ç»Ÿè®¡æœ€å¸¸è§çš„å€¼
    most_common_date = Counter(dates).most_common(1)[0][0] if dates else "æœªæä¾›"
    most_common_location = Counter(locations).most_common(1)[0][0] if locations else "Teams ç·šä¸Šæœƒè­°"
    most_common_duration = Counter(durations).most_common(1)[0][0] if durations else "æœªè¨˜éŒ„"
    most_common_name = Counter(meeting_names).most_common(1)[0][0] if meeting_names else "BSS ç¶“ç‡Ÿç®¡ç†æœƒè­°"

    # æ¸…ç†ä¸ä¼šè€…åˆ—è¡¨
    cleaned_attendees = sorted(list(attendees))

    return {
        'meeting_name': most_common_name,
        'date': most_common_date,
        'location': most_common_location,
        'duration': most_common_duration,
        'attendees': cleaned_attendees
    }


# ==================== å†…å®¹æ¸…ç† ====================

def remove_first_h2_title(content: str) -> str:
    """åˆ é™¤ç¬¬ä¸€ä¸ª ## æ ‡é¢˜"""
    lines = content.split('\n')
    result = []
    first_h2_removed = False

    for line in lines:
        if not first_h2_removed and line.strip().startswith('## '):
            first_h2_removed = True
            continue
        result.append(line)

    return '\n'.join(result)


def clean_content(content: str) -> str:
    """æ¸…ç†å†…å®¹ä¸­çš„æ ¼å¼é—®é¢˜"""

    # 1. åˆ é™¤æ—¥æœŸ/æ—¶é—´/åœ°ç‚¹ç­‰å…ƒæ•°æ®è¡Œï¼ˆå°†åœ¨ç»Ÿä¸€çš„å¼€å¤´ä¸­å±•ç¤ºï¼‰
    content = re.sub(r'\*\*æ—¥æœŸ[ï¼š:]\*\*[^\n]*\n?', '', content)
    content = re.sub(r'\*\*æ™‚é–“[ï¼š:]\*\*[^\n]*\n?', '', content)
    content = re.sub(r'\*\*åœ°é»[ï¼š:]\*\*[^\n]*\n?', '', content)
    content = re.sub(r'\*\*èˆ‡æœƒè€…[ï¼š:]\*\*[^\n]*\n?', '', content)
    content = re.sub(r'\*\*æœƒè­°åç¨±[ï¼š:]\*\*[^\n]*\n?', '', content)
    content = re.sub(r'\*\*å½¢å¼[ï¼š:]\*\*[^\n]*\n?', '', content)
    content = re.sub(r'\*\*éŒ„è£½æ™‚é–“[ï¼š:]\*\*[^\n]*\n?', '', content)
    content = re.sub(r'\*\*è¨˜éŒ„äºº[ï¼š:]\*\*[^\n]*\n?', '', content)

    # 2. åˆ é™¤å ä½ç¬¦
    content = re.sub(r'\([æœªæä¾›è£œå……è«‹]*[^)]*[ï¼‰)]', '', content)

    # 3. åˆ é™¤ "ä¸€ã€äºŒã€ä¸‰ã€" ç­‰ç¼–å·ï¼ˆä¿ç•™å±‚çº§ä½†å»æ‰ä¸­æ–‡æ•°å­—ï¼‰
    content = re.sub(r'\*\*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€\s*', '**', content)

    # 4. åˆ é™¤ "æœƒè­°åŸºæœ¬è³‡è¨Š" ç­‰æ ‡é¢˜
    content = re.sub(r'\*\*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€æœƒè­°åŸºæœ¬è³‡è¨Š\*\*\n?', '', content)
    content = re.sub(r'\*\*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€èˆ‡æœƒäººå“¡\*\*\n?', '', content)

    # 5. æ¸…ç†å¤šä½™ç©ºè¡Œ
    content = re.sub(r'\n{3,}', '\n\n', content)

    return content.strip()


def extract_topic_name(md_file: Path) -> str:
    """ä»æ–‡ä»¶åæå–ä¸»é¢˜åç§°"""
    name = md_file.stem

    # å»é™¤ _cleaned åç¼€
    name = name.replace('_cleaned', '')

    # å°†ä¸‹åˆ’çº¿æ›¿æ¢ä¸ºç©ºæ ¼
    name = name.replace('_', ' / ')

    return name


# ==================== æ ¼å¼åŒ–è¾“å‡º ====================

def format_attendees(attendees: List[str], max_show: int = 10) -> str:
    """æ ¼å¼åŒ–ä¸ä¼šè€…åˆ—è¡¨"""
    if not attendees:
        return "ï¼ˆè©³è¦‹å„ä¸»é¡Œï¼‰"

    if len(attendees) <= max_show:
        return 'ã€'.join(attendees)
    else:
        return 'ã€'.join(attendees[:max_show]) + f' ç­‰ {len(attendees)} äºº'


def create_report_header(metadata: Dict, topic_count: int) -> str:
    """åˆ›å»ºæŠ¥å‘Šå¤´éƒ¨"""

    header = f"""# BSS ç¶“ç‡Ÿç®¡ç†æœƒè­° - ä¸»é¡Œåˆ†é¡å ±å‘Š

**æœƒè­°åç¨±**: {metadata['meeting_name']}
**æ—¥æœŸ**: {metadata['date']}
**åœ°é»**: {metadata['location']}
**æœƒè­°æ™‚é•·**: {metadata['duration']}
**èˆ‡æœƒè€…**: {format_attendees(metadata['attendees'])}

---

## æœƒè­°æ‘˜è¦

æœ¬æ¬¡æœƒè­°è¨è«–äº† **{topic_count} å€‹ä¸»è¦è­°é¡Œ**ï¼Œæ¶µè“‹è²¡å‹™æ”¶æ¬¾ã€å°ˆæ¡ˆé€²åº¦ã€æ¡è³¼æ¨™æ¡ˆã€æŠ€è¡“åˆä½œã€ç³»çµ±ç®¡ç†ç­‰å¤šå€‹é¢å‘ã€‚ä»¥ä¸‹æŒ‰ä¸»é¡Œåˆ†é¡æ•´ç†æœƒè­°é‡é»ã€‚

---

"""

    return header


# ==================== ä¸»æµç¨‹ ====================

def merge_clean_topics(md_files: List[Path], sorted_order: List[str], output_path: Path):
    """åˆå¹¶å¹¶æ¸…ç†ä¸»é¢˜æŠ¥å‘Š"""

    print("="*60)
    print("ğŸš€ é–‹å§‹åˆä½µä¸¦æ¸…ç†ä¸»é¡Œå ±å‘Š")
    print("="*60)

    # 1. æå–å…ƒæ•°æ®
    print("\nğŸ“Š æå–æœƒè­°å…ƒæ•¸æ“š...")
    metadata = extract_metadata_from_files(md_files)
    print(f"  âœ… æœƒè­°åç¨±: {metadata['meeting_name']}")
    print(f"  âœ… æ—¥æœŸ: {metadata['date']}")
    print(f"  âœ… åœ°é»: {metadata['location']}")
    print(f"  âœ… èˆ‡æœƒè€…: {len(metadata['attendees'])} äºº")

    # 2. åˆ›å»ºæ–‡ä»¶ååˆ°è·¯å¾„çš„æ˜ å°„
    file_map = {f.name: f for f in md_files}

    # 3. æŒ‰æ’åºè·å–æ–‡ä»¶
    ordered_files = []
    for fname in sorted_order:
        if fname in file_map:
            ordered_files.append(file_map[fname])
        else:
            print(f"  âš ï¸  è­¦å‘Šï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {fname}")

    print(f"\nğŸ“ è™•ç† {len(ordered_files)} å€‹ä¸»é¡Œ...")

    # 4. ç”ŸæˆæŠ¥å‘Šå¤´éƒ¨
    report = create_report_header(metadata, len(ordered_files))

    # 5. é€ä¸ªå¤„ç†ä¸»é¢˜
    for i, md_file in enumerate(ordered_files, 1):
        print(f"  {i}. {md_file.name}")

        # è¯»å–å†…å®¹
        with open(md_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # æ¸…ç†å†…å®¹
        content = remove_first_h2_title(content)
        content = clean_content(content)

        # æå–ä¸»é¢˜å
        topic_name = extract_topic_name(md_file)

        # æ·»åŠ åˆ°æŠ¥å‘Š
        report += f"\n## {i}. {topic_name}\n\n"
        report += content
        report += "\n\n---\n\n"

    # 6. ä¿å­˜
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"\nâœ… å ±å‘Šå·²ç”Ÿæˆï¼š{output_path}")

    # 7. ç»Ÿè®¡
    file_size = output_path.stat().st_size / 1024
    with open(output_path, 'r', encoding='utf-8') as f:
        line_count = len(f.readlines())

    print(f"ğŸ“Š ç¸½è¡Œæ•¸ï¼š{line_count}")
    print(f"ğŸ“¦ æª”æ¡ˆå¤§å°ï¼š{file_size:.1f} KB")


# ==================== ä¸»ç¨‹åº ====================

def main():
    parser = argparse.ArgumentParser(
        description='å¿«é€Ÿä¿®å¾©ä¸¦åˆä½µä¸»é¡Œåˆ†é¡å ±å‘Š'
    )

    # è¾“å…¥æ–¹å¼ 1ï¼šæŒ‡å®šç›®å½•
    parser.add_argument('--input-dir', help='åŒ…å« MD æ–‡ä»¶çš„ç›®å½•')

    # è¾“å…¥æ–¹å¼ 2ï¼šä» judgment ç»“æœè¯»å–
    parser.add_argument('--from-judgment', help='ä» topic_judgments.json è¯»å–')

    # è¾“å‡º
    parser.add_argument('--output', default='topic_report_clean.md',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    # ==================== è·å–æ–‡ä»¶åˆ—è¡¨ ====================

    if args.from_judgment:
        # ä» judgment JSON è¯»å–
        judgment_file = Path(args.from_judgment)
        if not judgment_file.exists():
            print(f"âŒ Judgment æ–‡ä»¶ä¸å­˜åœ¨ï¼š{judgment_file}")
            return

        with open(judgment_file, 'r', encoding='utf-8') as f:
            judgments = json.load(f)

        input_dir = judgment_file.parent
        kept_files = [
            input_dir / j['filename']
            for j in judgments if j['keep']
        ]

        # è¯»å–æ’åºï¼ˆä» final_report.mdï¼‰
        final_report = input_dir / 'final_report.md'
        if final_report.exists():
            with open(final_report, 'r', encoding='utf-8') as f:
                content = f.read()

            # æå–é¡ºåº
            sorted_filenames = []
            for match in re.finditer(r'## \d+\. (.+)', content):
                topic_name = match.group(1).strip()
                # åŒ¹é…æ–‡ä»¶å
                for f in kept_files:
                    if topic_name.replace(' ', '_') in f.name or \
                       topic_name.replace(' / ', '_') in f.name:
                        if f.name not in sorted_filenames:
                            sorted_filenames.append(f.name)
                            break

            # æ·»åŠ æœªåŒ¹é…çš„
            for f in kept_files:
                if f.name not in sorted_filenames:
                    sorted_filenames.append(f.name)
        else:
            sorted_filenames = [f.name for f in sorted(kept_files, key=lambda x: x.name)]

        md_files = kept_files

    elif args.input_dir:
        # ä»ç›®å½•è¯»å–
        input_dir = Path(args.input_dir)
        if not input_dir.exists():
            print(f"âŒ ç›®éŒ„ä¸å­˜åœ¨ï¼š{input_dir}")
            return

        all_md_files = list(input_dir.glob('*.md'))
        exclude_keywords = ['CLAUDE', 'README', 'PATENT', 'cleaned', 'final', 'integrated', 'timeline', 'topic_report']

        md_files = [
            f for f in all_md_files
            if not any(exc in f.name for exc in exclude_keywords)
        ]

        if not md_files:
            print(f"âŒ åœ¨ {input_dir} ä¸­æœªæ‰¾åˆ° MD æ–‡ä»¶")
            return

        sorted_filenames = [f.name for f in sorted(md_files, key=lambda x: x.name)]

    else:
        print("âŒ è«‹æŒ‡å®š --input-dir æˆ– --from-judgment")
        return

    # ==================== ç¡®å®šè¾“å‡ºè·¯å¾„ ====================

    if args.output == 'topic_report_clean.md':
        if args.from_judgment:
            output_path = judgment_file.parent / args.output
        else:
            output_path = input_dir / args.output
    else:
        output_path = Path(args.output)

    # ==================== æ‰§è¡Œåˆå¹¶ ====================

    merge_clean_topics(md_files, sorted_filenames, output_path)

    print("\n" + "="*60)
    print("ğŸ‰ å®Œæˆï¼")
    print("="*60)


if __name__ == '__main__':
    main()
