#!/usr/bin/env python3
"""
main_part2_test.py - æµ‹è¯•ä¸»é¢˜ MD åˆå¹¶åŠŸèƒ½

åŠŸèƒ½ï¼š
1. é€ä¸ªåˆ¤æ–­ MD æ–‡ä»¶çš„ä»·å€¼ï¼ˆé€‚åˆ Gemma3ï¼Œæ¯æ¬¡ â‰¤ 4000 å­—ï¼‰
2. æ ¹æ®æ‘˜è¦æ’åºä¸»é¢˜
3. åˆå¹¶æˆå•ä¸€ä¼šè®®è®°å½•

ç”¨æ³•ï¼š
python main_part2_test.py --input-dir /path/to/md/files
"""

import argparse
import os
import re
import json
import time
import threading
from pathlib import Path
from typing import List, Dict, Tuple
import ollama
from zhconv_rs import zhconv
from config import BACK_END_MODEL, AI_MODEL, OLLAMA_URL


# ==================== AI äº¤äº’å‡½æ•° ====================

def print_dot(stop_event):
    """æ˜¾ç¤ºè¿›åº¦ç‚¹"""
    while not stop_event.is_set():
        print('.', end='', flush=True)
        time.sleep(0.8)


def ai_response(messages, max_tokens=1000):
    """è°ƒç”¨ AI æ¨¡å‹"""
    if BACK_END_MODEL == 'openai':
        from openai import OpenAI
        client = OpenAI()
        resp = client.chat.completions.create(
            model=AI_MODEL,
            messages=messages,
            max_tokens=max_tokens
        )
        text = resp.choices[0].message.content
    else:
        client = ollama.Client(host=OLLAMA_URL)
        resp = client.chat(
            model=AI_MODEL,
            messages=messages
        )
        text = resp['message']['content']

    # ç§»é™¤ deepseek çš„ <think> æ ‡ç­¾
    if AI_MODEL.startswith('deepseek'):
        text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)

    return zhconv(text.strip(), 'zh-tw')


# ==================== æ­¥éª¤ 7.1ï¼šä»·å€¼åˆ¤æ–­ ====================

SYSTEM_PROMPT_FILTER = """ä½ æ˜¯æœƒè­°è¨˜éŒ„å¯©æŸ¥å°ˆå®¶ã€‚
è«‹åˆ¤æ–·é€™å€‹æœƒè­°ä¸»é¡Œæ˜¯å¦æ‡‰è©²ä¿ç•™åœ¨æ­£å¼æœƒè­°è¨˜éŒ„ä¸­ã€‚

ã€ä¿ç•™æ¨™æº–ã€‘(true)ï¼š
- åŒ…å«å¯¦è³ªæ¥­å‹™å…§å®¹ï¼ˆå°ˆæ¡ˆã€è²¡å‹™ã€æ¡è³¼ã€åˆç´„ç­‰ï¼‰
- æœ‰æ˜ç¢ºçš„æ±ºè­°ã€è¡Œå‹•é …ç›®æˆ–é‡è¦è¨è«–
- æ¶‰åŠé‡‘éŒ¢ã€æ™‚ç¨‹ã€äººå“¡å®‰æ’ç­‰é—œéµè³‡è¨Š

ã€ç§»é™¤æ¨™æº–ã€‘(false)ï¼š
- åƒ…æ˜¯ç°¡å–®çš„äººäº‹å•å€™ã€æ„Ÿè¬
- æ¨™è¨»ç‚ºã€ŒéŒ¯èª¤ã€ã€ã€Œç„¡é—œã€çš„å…§å®¹
- ç„¡å¯¦è³ªå…§å®¹çš„æŠ€è¡“å•é¡Œè¨˜éŒ„
- éæ–¼ç‘£ç¢çš„ç´°ç¯€

è«‹åªå›è¦† JSON æ ¼å¼ï¼ˆä¸è¦å…¶ä»–èªªæ˜ï¼‰ï¼š
{"keep": true, "reason": "ä¸€å¥è©±èªªæ˜åŸå› "}
æˆ–
{"keep": false, "reason": "ä¸€å¥è©±èªªæ˜åŸå› "}
"""


def judge_topic_value(md_file: Path) -> Dict:
    """
    åˆ¤æ–­å•ä¸ªä¸»é¢˜çš„ä»·å€¼

    è¿”å›: {"keep": true/false, "reason": "..."}
    """
    # è¯»å–æ–‡ä»¶å†…å®¹
    with open(md_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æ£€æŸ¥å­—æ•°ï¼ˆGemma3 é™åˆ¶ï¼‰
    char_count = len(content)
    if char_count > 4000:
        print(f"âš ï¸  è­¦å‘Šï¼š{md_file.name} è¶…é 4000 å­—ï¼ˆ{char_count} å­—ï¼‰ï¼Œå¯èƒ½å½±éŸ¿åˆ¤æ–·æº–ç¢ºåº¦")

    # æ„å»º prompt
    user_prompt = f"""ä¸»é¡Œæª”åï¼š{md_file.name}

å…§å®¹ï¼š
{content}

è«‹åˆ¤æ–·æ˜¯å¦ä¿ç•™æ­¤ä¸»é¡Œã€‚"""

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT_FILTER},
        {"role": "user", "content": user_prompt}
    ]

    # è°ƒç”¨ AIï¼ˆå¸¦è¿›åº¦ç‚¹ï¼‰
    print(f"\nğŸ¤” åˆ¤æ–·ï¼š{md_file.name} ({char_count} å­—)", end='')
    stop_event = threading.Event()
    dot_thread = threading.Thread(target=print_dot, args=(stop_event,))
    dot_thread.start()

    try:
        response = ai_response(messages, max_tokens=200)
    finally:
        stop_event.set()
        dot_thread.join()

    # è§£æ JSON
    try:
        # å°è¯•ç›´æ¥è§£æ
        result = json.loads(response)
    except json.JSONDecodeError:
        # å°è¯•æå– JSON éƒ¨åˆ†
        json_match = re.search(r'\{.*?\}', response, re.DOTALL)
        if json_match:
            result = json.loads(json_match.group())
        else:
            # å¦‚æœå®Œå…¨å¤±è´¥ï¼Œæ‰‹åŠ¨åˆ¤æ–­
            print(f"\nâš ï¸  ç„¡æ³•è§£æå›æ‡‰ï¼Œä½¿ç”¨é è¨­åˆ¤æ–·")
            if 'éŒ¯èª¤' in md_file.name or 'ç„¡é—œ' in md_file.name or 'æ„Ÿè¬' in md_file.name:
                result = {"keep": False, "reason": "æ ¹æ“šæª”ååˆ¤æ–·"}
            else:
                result = {"keep": True, "reason": "æ ¹æ“šæª”ååˆ¤æ–·"}

    # æ·»åŠ æ–‡ä»¶ä¿¡æ¯
    result['filename'] = md_file.name
    result['char_count'] = char_count

    # æ˜¾ç¤ºç»“æœ
    emoji = "âœ…" if result['keep'] else "âŒ"
    print(f" {emoji} {result['reason']}")

    return result


# ==================== æ­¥éª¤ 7.2ï¼šæ’åº ====================

SYSTEM_PROMPT_ORDER = """ä½ æ˜¯æœƒè­°æµç¨‹å°ˆå®¶ã€‚
è«‹æ ¹æ“šåˆç†çš„æœƒè­°æµç¨‹ï¼Œç‚ºé€™äº›ä¸»é¡Œæ’åºã€‚

ã€ä¸€èˆ¬æœƒè­°é †åºã€‘ï¼š
1. é‡è¦å ±å‘Šï¼ˆè²¡å‹™ã€å°ˆæ¡ˆé€²åº¦ï¼‰
2. è¨è«–è­°é¡Œï¼ˆæ¡è³¼ã€åˆç´„ï¼‰
3. è¡Œæ”¿äº‹é …ï¼ˆæª”æ¡ˆã€å ±å‘Šè™•ç†ï¼‰
4. åˆè¦äº‹é …ï¼ˆæ¶ˆé˜²ã€å®‰å…¨ï¼‰
5. å…¶ä»–äº‹é …

è«‹åªå›è¦†æª”åçš„é †åºåˆ—è¡¨ï¼Œç”¨é€—è™Ÿåˆ†éš”ï¼Œä¾‹å¦‚ï¼š
å°ˆæ¡ˆé€²åº¦èˆ‡è²¡å‹™.md,æ¡è³¼_åˆç´„_è¨‚å–®.md,æª”æ¡ˆ_éƒµä»¶_å ±å‘Šè™•ç†.md

ä¸è¦å…¶ä»–èªªæ˜ï¼Œåªè¦æª”ååˆ—è¡¨ã€‚
"""


def sort_topics(md_files: List[Path]) -> List[Path]:
    """
    æ ¹æ®ä¸»é¢˜æ‘˜è¦æ’åº

    ä¸ºäº†æ§åˆ¶ Gemma3 çš„è¾“å…¥é•¿åº¦ï¼Œæ¯ä¸ªä¸»é¢˜åªå–å‰ 200 å­—ä½œä¸ºæ‘˜è¦
    """
    # æ„å»ºæ‘˜è¦
    summaries = []
    for f in md_files:
        with open(f, 'r', encoding='utf-8') as file:
            content = file.read()
            preview = content[:200] + '...' if len(content) > 200 else content
            summaries.append(f"ã€{f.name}ã€‘\n{preview}")

    summaries_text = "\n\n".join(summaries)
    total_chars = len(summaries_text)

    print(f"\nğŸ“Š æ’åºä»»å‹™ï¼š{len(md_files)} å€‹ä¸»é¡Œï¼Œç¸½è¨ˆ {total_chars} å­—")

    if total_chars > 3000:
        print(f"âš ï¸  è­¦å‘Šï¼šæ‘˜è¦ç¸½é•·åº¦è¶…é 3000 å­—ï¼Œå¯èƒ½å½±éŸ¿æ’åºæº–ç¢ºåº¦")

    user_prompt = f"""ä»¥ä¸‹æ˜¯å„ä¸»é¡Œçš„æ‘˜è¦ï¼š

{summaries_text}

è«‹çµ¦å‡ºåˆç†çš„æ’åºï¼ˆåªè¦æª”åï¼Œç”¨é€—è™Ÿåˆ†éš”ï¼‰ã€‚"""

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT_ORDER},
        {"role": "user", "content": user_prompt}
    ]

    # è°ƒç”¨ AI
    print(f"ğŸ¤” æ­£åœ¨æ’åº", end='')
    stop_event = threading.Event()
    dot_thread = threading.Thread(target=print_dot, args=(stop_event,))
    dot_thread.start()

    try:
        response = ai_response(messages, max_tokens=500)
    finally:
        stop_event.set()
        dot_thread.join()

    print(f" âœ…")

    # è§£æå›åº”ï¼ˆæå–æ–‡ä»¶åï¼‰
    # å°è¯•æŒ‰é€—å·åˆ†å‰²
    filenames = [name.strip() for name in response.split(',')]

    # æ„å»ºæ–‡ä»¶ååˆ°è·¯å¾„çš„æ˜ å°„
    file_map = {f.name: f for f in md_files}

    # æŒ‰é¡ºåºæ’åˆ—ï¼ˆå¿½ç•¥ä¸å­˜åœ¨çš„æ–‡ä»¶åï¼‰
    sorted_files = []
    for fname in filenames:
        if fname in file_map:
            sorted_files.append(file_map[fname])

    # æ·»åŠ æœªè¢«æ’åºçš„æ–‡ä»¶ï¼ˆé˜²æ­¢é—æ¼ï¼‰
    for f in md_files:
        if f not in sorted_files:
            sorted_files.append(f)
            print(f"âš ï¸  {f.name} æœªè¢« AI æ’åºï¼Œè¿½åŠ åˆ°æœ«å°¾")

    return sorted_files


# ==================== æ­¥éª¤ 7.3ï¼šåˆå¹¶ ====================

def merge_reports(sorted_files: List[Path], output_path: Path):
    """
    åˆå¹¶æŠ¥å‘Šï¼ˆç®€å•æ‹¼æ¥ï¼Œä¸éœ€è¦ AIï¼‰
    """
    print(f"\nğŸ“ åˆä½µ {len(sorted_files)} å€‹ä¸»é¡Œåˆ°ï¼š{output_path}")

    with open(output_path, 'w', encoding='utf-8') as out:
        # å†™å…¥æ ‡é¢˜
        out.write("# æœƒè­°è¨˜éŒ„\n\n")
        out.write(f"**ä¸»é¡Œæ•¸é‡ï¼š** {len(sorted_files)}\n\n")
        out.write("---\n\n")

        # é€ä¸ªå†™å…¥ä¸»é¢˜
        for i, md_file in enumerate(sorted_files, 1):
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read().strip()

            # æå–ä¸»é¢˜åç§°ï¼ˆä»æ–‡ä»¶åï¼‰
            topic_name = md_file.stem.replace('_', ' ')

            print(f"  {i}. {topic_name}")

            out.write(f"## {i}. {topic_name}\n\n")
            out.write(content)
            out.write("\n\n")

            # æ·»åŠ åˆ†éš”çº¿ï¼ˆé™¤äº†æœ€åä¸€ä¸ªï¼‰
            if i < len(sorted_files):
                out.write("---\n\n")

    print(f"\nâœ… åˆä½µå®Œæˆï¼")


# ==================== ä¸»æµç¨‹ ====================

def main():
    parser = argparse.ArgumentParser(description='æµ‹è¯•ä¸»é¢˜ MD åˆå¹¶åŠŸèƒ½')
    parser.add_argument('--input-dir', required=True, help='åŒ…å« MD æ–‡ä»¶çš„ç›®å½•')
    parser.add_argument('--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šinput-dir/final_report.mdï¼‰')
    parser.add_argument('--skip-filter', action='store_true', help='è·³è¿‡ä»·å€¼åˆ¤æ–­ï¼Œä¿ç•™æ‰€æœ‰ä¸»é¢˜')
    parser.add_argument('--skip-sort', action='store_true', help='è·³è¿‡æ’åºï¼ŒæŒ‰æ–‡ä»¶åæ’åº')
    args = parser.parse_args()

    start_time = time.time()

    # è·å–æ‰€æœ‰ MD æ–‡ä»¶
    input_dir = Path(args.input_dir)
    all_md_files = list(input_dir.glob('*.md'))

    # æ’é™¤ç³»ç»Ÿæ–‡ä»¶
    exclude_keywords = ['CLAUDE', 'README', 'PATENT', 'cleaned', 'final']
    md_files = [
        f for f in all_md_files
        if not any(exc in f.name for exc in exclude_keywords)
    ]

    if not md_files:
        print(f"âŒ åœ¨ {input_dir} ä¸­æœªæ‰¾åˆ° MD æ–‡ä»¶")
        return

    print("="*60)
    print("ğŸš€ é–‹å§‹æ¸¬è©¦ä¸»é¡Œåˆä½µåŠŸèƒ½")
    print("="*60)
    print(f"ğŸ“ è¼¸å…¥ç›®éŒ„ï¼š{input_dir}")
    print(f"ğŸ“„ æ‰¾åˆ° {len(md_files)} å€‹ä¸»é¡Œæª”æ¡ˆï¼š")
    for f in md_files:
        size_kb = f.stat().st_size / 1024
        print(f"  - {f.name} ({size_kb:.1f} KB)")

    # ==================== æ­¥éª¤ 7.1ï¼šä»·å€¼åˆ¤æ–­ ====================
    if not args.skip_filter:
        print("\n" + "="*60)
        print("ğŸ“‹ æ­¥é©Ÿ 7.1ï¼šåƒ¹å€¼åˆ¤æ–·")
        print("="*60)

        judgments = []
        for md_file in md_files:
            result = judge_topic_value(md_file)
            judgments.append(result)

        # ä¿å­˜åˆ¤æ–­ç»“æœ
        judgment_file = input_dir / 'topic_judgments.json'
        with open(judgment_file, 'w', encoding='utf-8') as f:
            json.dump(judgments, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ åˆ¤æ–·çµæœå·²å„²å­˜ï¼š{judgment_file}")

        # è¿‡æ»¤
        kept_files = [
            Path(input_dir / j['filename'])
            for j in judgments if j['keep']
        ]
        removed_files = [
            Path(input_dir / j['filename'])
            for j in judgments if not j['keep']
        ]

        print(f"\nğŸ“Š éæ¿¾çµæœï¼š")
        print(f"  âœ… ä¿ç•™ï¼š{len(kept_files)} å€‹")
        print(f"  âŒ ç§»é™¤ï¼š{len(removed_files)} å€‹")

        if removed_files:
            print(f"\nâŒ å·²ç§»é™¤çš„ä¸»é¡Œï¼š")
            for f in removed_files:
                reason = next(j['reason'] for j in judgments if j['filename'] == f.name)
                print(f"  - {f.name}: {reason}")

        md_files = kept_files

    # ==================== æ­¥éª¤ 7.2ï¼šæ’åº ====================
    if not args.skip_sort and len(md_files) > 1:
        print("\n" + "="*60)
        print("ğŸ“‹ æ­¥é©Ÿ 7.2ï¼šä¸»é¡Œæ’åº")
        print("="*60)

        sorted_files = sort_topics(md_files)

        print(f"\nğŸ“ æ’åºçµæœï¼š")
        for i, f in enumerate(sorted_files, 1):
            print(f"  {i}. {f.name}")
    else:
        # æŒ‰æ–‡ä»¶åæ’åº
        sorted_files = sorted(md_files, key=lambda x: x.name)
        print(f"\nâ­ï¸  è·³éæ’åºï¼Œä½¿ç”¨æª”åé †åº")

    # ==================== æ­¥éª¤ 7.3ï¼šåˆå¹¶ ====================
    print("\n" + "="*60)
    print("ğŸ“‹ æ­¥é©Ÿ 7.3ï¼šåˆä½µå ±å‘Š")
    print("="*60)

    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if args.output:
        output_path = Path(args.output)
    else:
        output_path = input_dir / 'Final_report.md'

    merge_reports(sorted_files, output_path)

    # ==================== æ€»ç»“ ====================
    elapsed = time.time() - start_time
    print("\n" + "="*60)
    print("ğŸ‰ æ¸¬è©¦å®Œæˆï¼")
    print("="*60)
    print(f"â±ï¸  ç¸½è€—æ™‚ï¼š{elapsed:.1f} ç§’")
    print(f"ğŸ“„ æœ€çµ‚å ±å‘Šï¼š{output_path}")
    print(f"ğŸ“Š åŒ…å«ä¸»é¡Œæ•¸ï¼š{len(sorted_files)}")

    # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
    if output_path.exists():
        size_kb = output_path.stat().st_size / 1024
        print(f"ğŸ“¦ æª”æ¡ˆå¤§å°ï¼š{size_kb:.1f} KB")


if __name__ == '__main__':
    main()
