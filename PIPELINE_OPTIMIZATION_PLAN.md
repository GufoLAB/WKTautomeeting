# Topic ç‰ˆ Pipeline å„ªåŒ–æ–¹æ¡ˆ
## åœ¨ Gemma3 27B 2000ä¸­æ–‡å­—çª—å£é™åˆ¶ä¸‹è¿½æ±‚ Claude ç‰ˆå“è³ª

**ç›®æ¨™**: å°‡ Topic ç‰ˆå¾ 86åˆ† æå‡åˆ° 92-95åˆ†
**ç´„æŸ**: Gemma3 27B æ™ºèƒ½çª—å£åƒ… 2000 ä¸­æ–‡å­—
**ç¾ç‹€**: Topic ç‰ˆè³‡è¨Šå®Œæ•´åº¦ 76%ï¼Œæ±ºç­–å®Œæ•´åº¦ 80%

---

## ğŸ” Pipeline ç¾ç‹€è¨ºæ–·

### å®Œæ•´æµç¨‹è§£æ

```
æ­¥é©Ÿ1: topic_spliter (æœªåˆ†æ)
  â””â”€> ç”¢å‡º: topic_01.md, topic_02.md...

æ­¥é©Ÿ2: 2chunks_summary.py
  è¼¸å…¥: æ¯å€‹ topic_XX.md
  é™åˆ¶: MAX_CHARS = 6000 (ä½†å¯¦éš›è™•ç†ä¸è¶…é 2000)
  Prompt: "ç”¨ä¸è¶…é100å­—æº–ç¢ºæ‘˜è¦é€å­—ç¨¿çš„é‡é»äº‹é …"
  è¼¸å‡º: chunks_summaries.csv (chunk_id, summary, text)
  â””â”€> ç”¢å‡º: chunks_summaries_brief.csv

æ­¥é©Ÿ3: 3brief_summary_reindex.py
  è™•ç†: æ¸…ç†å¤šé¤˜æ›è¡Œã€é‡æ–°ç·¨è™Ÿ chunk_id
  å½±éŸ¿: âŒ ç§»é™¤äº†åŸå§‹ text æ¬„ä½ï¼
  â””â”€> ç”¢å‡º: chunks_summaries_brief_reindexed.csv

æ­¥é©Ÿ4: 4Condense.py
  é™åˆ¶: MAX_CHARS = 1600
  Prompt 1: "ç”¨ 10 åˆ° 20 å€‹ä¸­æ–‡å­—ç¬¦ï¼Œç²¾ç…‰æ¦‚æ‹¬ä¸»é¡Œ"
  Prompt 2: "è«‹æ ¹æ“šèªæ„å°‡å®ƒå€‘åˆ†ç¾¤ï¼Œç¾¤æ•¸ 3â€“10"
  è¼¸å‡º: topicæ¬„ = "[chunk_id]ä¸»é¡Œå" (20å­—å…§)
  â””â”€> ç”¢å‡º: *_condense_topics.csv + clusters.json

æ­¥é©Ÿ5: pipeline_meeting_report.py
  è¼¸å…¥: *_condense_topics.csv (åªæœ‰ chunk_id, summary, topic, cluster_name)
  å•é¡Œ: âš ï¸ æ­¤æ™‚å·²ç¶“æ²’æœ‰åŸå§‹é€å­—ç¨¿ text äº†ï¼
  Prompt Init: "æ ¹æ“šå¤šæ¢100å­—å·¦å³çš„æœƒè­°æ‘˜è¦ï¼Œæ’°å¯« Markdown å ±å‘Š"
  Prompt Cont: "çµåˆå‰æ–‡æœ€å¾Œ15è¡Œèˆ‡æ–°çš„æ‘˜è¦"
  é™åˆ¶: åªèƒ½çœ‹ summary (100å­—) + å‰æ–‡15è¡Œ
  â””â”€> ç”¢å‡º: {cluster_name}.md

æ­¥é©Ÿ6: 8merge_clean_topics.py
  è™•ç†: æå–å…ƒæ•¸æ“šã€æ¸…ç†æ ¼å¼ã€åˆªé™¤é‡è¤‡æ¨™é¡Œ
  â””â”€> ç”¢å‡º: topic_report_clean.md

æ­¥é©Ÿ7: 9remove_duplicates.py
  è™•ç†: é€²ä¸€æ­¥å»é‡
  â””â”€> ç”¢å‡º: topic_report_clean_dedup.md
```

---

## ğŸ¯ é—œéµå•é¡Œè¨ºæ–·

### è‡´å‘½å•é¡Œ 1: è³‡è¨Šéºå¤±æ¼æ–—

```
åŸå§‹é€å­—ç¨¿ (100%)
    â†“ æ­¥é©Ÿ2: æ‘˜è¦åˆ° 100å­—
chunks_summary (60% è³‡è¨Šä¿ç•™)
    â†“ æ­¥é©Ÿ3: ç§»é™¤ text æ¬„ä½ âŒ
chunks_brief_reindexed (60% è³‡è¨Šä¿ç•™)
    â†“ æ­¥é©Ÿ4: å†æ¿ƒç¸®åˆ° 20å­—ä¸»é¡Œ
condense_topics (40% è³‡è¨Šä¿ç•™)
    â†“ æ­¥é©Ÿ5: åŸºæ–¼ 100å­—æ‘˜è¦ç”Ÿæˆå ±å‘Š
æœ€çµ‚å ±å‘Š (40-50% è³‡è¨Šä¿ç•™)
```

**å•é¡Œæ ¹æº**: æ­¥é©Ÿ3 åˆªé™¤äº† `text` æ¬„ä½ï¼Œå°è‡´æ­¥é©Ÿ5 åªèƒ½çœ‹ 100å­—æ‘˜è¦

### è‡´å‘½å•é¡Œ 2: Prompt è¨­è¨ˆä¸è¶³

**æ­¥é©Ÿ2 Prompt** (2chunks_summary.py:60):
```python
"è«‹ç”¨ä¸è¶…é100å­—æº–ç¢ºæ‘˜è¦é€å­—ç¨¿çš„é‡é»äº‹é …ï¼Œ
åŒ…å«é‡è¦æ•¸å­—ã€åç¨±ã€äººäº‹æ™‚åœ°ç‰©èˆ‡å–®ä½ï¼Œç„¡æˆ–ç„¡é—œå‰‡ä¸å¯«ã€‚"
```

**å•é¡Œåˆ†æ**:
- âŒ æ²’æœ‰è¦æ±‚ä¿ç•™**æ±ºç­–éç¨‹**
- âŒ æ²’æœ‰è¦æ±‚ä¿ç•™**è²¬ä»»æ­¸å±¬**
- âŒ æ²’æœ‰è¦æ±‚ä¿ç•™**æ™‚ç¨‹æ‰¿è«¾**
- âŒ 100å­—é™åˆ¶éåš´ï¼Œå°è‡´å¿…é ˆæ¨æ£„ç´°ç¯€

**å°æ¯” Claude ç‰ˆ**: Claude çœ‹å®Œæ•´é€å­—ç¨¿ï¼Œå¯ä»¥ç†è§£ï¼š
- ç‚ºä»€éº¼åšé€™å€‹æ±ºç­–
- èª°è² è²¬åŸ·è¡Œ
- è¨è«–éç¨‹çš„é‚è¼¯

### è‡´å‘½å•é¡Œ 3: çºŒå¯«ç­–ç•¥ç¼ºé™·

**pipeline_meeting_report.py:121-126**:
```python
# è®€æª”å–æœ€å¾Œ context
with open(out_md, 'r', encoding='utf-8') as f:
    lines = f.readlines()
context = lines[-15:] if len(lines)>=15 else lines
```

**å•é¡Œ**:
1. æœ€å¾Œ15è¡Œå¯èƒ½åªæ˜¯åˆ—è¡¨é …ï¼Œç¼ºä¹èªå¢ƒ
2. æ–°æ‘˜è¦åªæœ‰ 100å­—ï¼Œç„¡æ³•è£œå……å®Œæ•´ç´°ç¯€
3. AI è¢«è¿«ã€Œæ¨æ¸¬ã€ç¼ºå¤±çš„è³‡è¨Š

---

## ğŸ’¡ å„ªåŒ–æ–¹æ¡ˆï¼š7å¤§æ”¹é€²ç­–ç•¥

### ç­–ç•¥ 1: ä¿ç•™åŸå§‹æ–‡æœ¬éˆï¼ˆæœ€é‡è¦ï¼‰

**ä¿®æ”¹ 3brief_summary_reindex.py**:

```python
# === Step 2.5: ä¸è¦åˆªé™¤ text æ¬„ä½ï¼===
if 'summary' in df.columns:
    df['summary'] = df['summary'].astype(str).apply(lambda x: ' '.join(x.split()))
    df['chunk_id'] = range(1, len(df) + 1)

# === Step 4: ä¿ç•™ text æ¬„ä½ ===
df = df[['chunk_id', 'summary', 'text']]  # â† å¢åŠ  'text'
```

**å½±éŸ¿**: æ­¥é©Ÿ5 å¯ä»¥çœ‹åˆ°åŸå§‹é€å­—ç¨¿ç‰‡æ®µï¼ˆé›–ç„¶é•·ï¼Œä½†å¯ä»¥æ‘˜éŒ„ï¼‰

---

### ç­–ç•¥ 2: æ”¹é€²æ­¥é©Ÿ2æ‘˜è¦ Prompt

**ä¿®æ”¹ 2chunks_summary.py:60**:

#### åŸç‰ˆæœ¬ï¼ˆ100å­—ï¼‰:
```python
prompt = f"""é€å­—ç¨¿ç‰‡æ®µå…§å®¹å¦‚ä¸‹ï¼š\n{text}\n\n
ä½ æ˜¯æˆ‘å€‘å–®ä½çš„aiï¼Œè«‹ç”¨ä¸è¶…é100å­—æº–ç¢ºæ‘˜è¦é€å­—ç¨¿çš„é‡é»äº‹é …ï¼Œ
åŒ…å«é‡è¦æ•¸å­—ã€åç¨±ã€äººäº‹æ™‚åœ°ç‰©èˆ‡å–®ä½ï¼Œç„¡æˆ–ç„¡é—œå‰‡ä¸å¯«ã€‚"""
```

#### å„ªåŒ–ç‰ˆæœ¬ Aï¼ˆ150å­—åŠ å¼·ç‰ˆï¼‰:
```python
prompt = f"""é€å­—ç¨¿ç‰‡æ®µå…§å®¹å¦‚ä¸‹ï¼š\n{text}\n\n
ä½ æ˜¯å°ˆæ¥­æœƒè­°è¨˜éŒ„AIï¼Œè«‹ç”¨ 120-150å­— æ‘˜è¦æ­¤ç‰‡æ®µï¼Œå¿…é ˆåŒ…å«ï¼š
1. **æ‰€æœ‰æ•¸å­—èˆ‡é‡‘é¡**ï¼ˆæº–ç¢ºåˆ°å€‹ä½ï¼‰
2. **äººåèˆ‡è·ç¨±**ï¼ˆä¸­è‹±æ–‡å…¨åï¼‰
3. **æ±ºç­–äº‹é …**ï¼ˆèª°æ±ºå®šã€æ±ºå®šä»€éº¼ã€ä½•æ™‚åŸ·è¡Œï¼‰
4. **æ™‚ç¨‹èˆ‡æˆªæ­¢æ—¥**ï¼ˆå…·é«”æ—¥æœŸï¼‰
5. **å–®ä½åç¨±**ï¼ˆå®Œæ•´ä¸ç¸®å¯«ï¼‰
6. **å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ**ï¼ˆå¦‚æœæœ‰è¨è«–ï¼‰

æ ¼å¼è¦æ±‚ï¼šæ¢åˆ—å¼ã€æ•¸å­—ç”¨é˜¿æ‹‰ä¼¯æ•¸å­—ã€ä¿ç•™åŸæ–‡é—œéµè©ã€‚"""
```

**æ”¹é€²é»**:
- âœ… 150å­—çµ¦æ›´å¤šç©ºé–“
- âœ… æ˜ç¢ºè¦æ±‚ 6 å¤§è¦ç´ 
- âœ… å¼·èª¿ã€Œæ±ºç­–äº‹é …ã€èˆ‡ã€Œè²¬ä»»æ­¸å±¬ã€
- âœ… è¦æ±‚æ¢åˆ—å¼ï¼Œæ–¹ä¾¿å¾ŒçºŒè™•ç†

#### å„ªåŒ–ç‰ˆæœ¬ Bï¼ˆé›™æ®µå¼ 200å­—ï¼‰:
```python
prompt = f"""é€å­—ç¨¿ç‰‡æ®µï¼š\n{text}\n\n
è«‹åˆ†å…©æ®µæ‘˜è¦ï¼ˆç¸½å…± 180-200å­—ï¼‰ï¼š

ã€æ®µè½1: äº‹å¯¦èˆ‡æ•¸å­—ã€‘ï¼ˆ100-120å­—ï¼‰
- æ‰€æœ‰é‡‘é¡ã€æ•¸é‡ã€æ—¥æœŸã€äººåã€å–®ä½åç¨±
- æ ¼å¼ï¼šã€ŒXXXï¼ˆäººåï¼‰å ±å‘Šï¼šYYYæ¡ˆ ZZZè¬ï¼ŒWWæœˆäº¤ä»˜ã€

ã€æ®µè½2: æ±ºç­–èˆ‡è¡Œå‹•ã€‘ï¼ˆ80å­—ï¼‰
- èª°æ±ºå®šäº†ä»€éº¼
- èª°è² è²¬åŸ·è¡Œ
- ä½•æ™‚å®Œæˆ
- æ ¼å¼ï¼šã€Œæ±ºè­°ï¼šAAAè² è²¬BBBï¼ŒCCCæœˆå‰å®Œæˆã€

ç„¡ç›¸é—œå…§å®¹å‰‡è©²æ®µå¯«ã€Œç„¡ã€ã€‚"""
```

**å„ªå‹¢**:
- âœ… çµæ§‹åŒ–è¼¸å‡ºï¼Œä¾¿æ–¼å¾ŒçºŒè§£æ
- âœ… 200å­—å¯å®¹ç´æ›´å¤šç´°ç¯€
- âœ… æ˜ç¢ºåˆ†é›¢ã€Œäº‹å¯¦ã€èˆ‡ã€Œæ±ºç­–ã€

---

### ç­–ç•¥ 3: å¢åŠ ã€Œé—œéµè³‡è¨Šæå–ã€æ­¥é©Ÿï¼ˆæ–°å¢æ­¥é©Ÿ 2.5ï¼‰

**å‰µå»ºæ–°æ–‡ä»¶ `2.5extract_key_info.py`**:

åœ¨æ­¥é©Ÿ2å¾Œã€æ­¥é©Ÿ3å‰ï¼Œé‡å° `summary` æ¬„ä½å†åšä¸€æ¬¡ã€Œé—œéµè³‡è¨Šçµæ§‹åŒ–ã€ï¼š

```python
def extract_structured_info(summary: str, original_text: str) -> dict:
    """å¾æ‘˜è¦ä¸­æå–çµæ§‹åŒ–è³‡è¨Š"""

    # åªåœ¨éœ€è¦æ™‚åƒè€ƒåŸæ–‡ï¼ˆä¸è¶…é 1000å­—ï¼‰
    context = original_text[:1000] if len(original_text) > 1000 else original_text

    prompt = f"""
æ‘˜è¦ï¼š{summary}

åŸæ–‡ç‰‡æ®µï¼ˆä¾›åƒè€ƒï¼‰ï¼š{context}

è«‹æå–ä»¥ä¸‹çµæ§‹åŒ–è³‡è¨Šï¼ˆJSONæ ¼å¼ï¼‰ï¼š
{{
  "é‡‘é¡": ["327è¬", "13è¬"],
  "æ—¥æœŸ": ["10æœˆ13æ—¥", "11æœˆåº•"],
  "äººå": ["ç¿åœ‹å€«", "è”¡å®—å“²"],
  "å–®ä½": ["è¡›ç¦éƒ¨", "åŒ—å¸‚æ•™è‚²å±€"],
  "æ±ºç­–": ["ç¿åœ‹å€«è¿½è¹¤è¡›ç¦éƒ¨æ¬¾é …"],
  "é—œéµè©": ["å»¶é²", "å°¾æ¬¾", "è¿½è¹¤"]
}}

è‹¥æŸé …ç„¡è³‡è¨Šï¼Œvalue ç‚ºç©ºåˆ—è¡¨ []ã€‚åªè¼¸å‡º JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
"""

    response = ai_response([{"role": "user", "content": prompt}], max_tokens=300)
    return json.loads(response)
```

**CSV æ–°å¢æ¬„ä½**:
```
chunk_id | summary | text | structured_info
```

**å„ªå‹¢**:
- âœ… Gemma3 è™•ç†çµæ§‹åŒ–ä»»å‹™è¡¨ç¾å¥½
- âœ… å¾ŒçºŒç”Ÿæˆæ™‚å¯ä»¥ç›´æ¥å¼•ç”¨æº–ç¢ºæ•¸å­—
- âœ… 300 token è¼¸å‡ºè¶³å¤ ï¼ˆç´„ 150 ä¸­æ–‡å­—ï¼‰

---

### ç­–ç•¥ 4: æ”¹é€²æ­¥é©Ÿ5ç”Ÿæˆ Prompt

**ä¿®æ”¹ pipeline_meeting_report.py çš„å…©å€‹ Prompt**:

#### åŸ SYSTEM_PROMPT_INIT (ä¸ä½³):
```python
SYSTEM_PROMPT_INIT = """
ä½ è² è²¬æ ¹æ“šå¤šæ¢100å­—å·¦å³çš„æœƒè­°æ‘˜è¦ï¼Œ
æ’°å¯«ä¸€æ®µæ¢åˆ—å¼çš„ Markdown æœƒè­°å ±å‘Šç¯€é¸ï¼Œ
å¿…é ˆè©³ç›¡åˆ—å‡ºäººäº‹æ™‚åœ°ç‰©èˆ‡é‡‘éŒ¢è²»ç”¨ç­‰ç´°ç¯€ï¼Œ
ä¸”èƒ½æ¸…æ™°å‘ˆç¾å„é‡é»ã€‚
"""
```

#### å„ªåŒ– SYSTEM_PROMPT_INIT:
```python
SYSTEM_PROMPT_INIT = """
ä½ æ˜¯å°ˆæ¥­æœƒè­°è¨˜éŒ„æ’°å¯«å°ˆå®¶ã€‚ä½ å°‡æ”¶åˆ°å¤šæ¢æœƒè­°æ‘˜è¦èˆ‡åŸå§‹é€å­—ç¨¿ç‰‡æ®µã€‚

ã€æ’°å¯«è¦æ±‚ã€‘ï¼š
1. **ä¿ç•™æ‰€æœ‰æ•¸å­—**ï¼šé‡‘é¡ã€ç™¾åˆ†æ¯”ã€æ•¸é‡ä¸€å¾‹ç²¾ç¢ºå¼•ç”¨
2. **å®Œæ•´äººåè·ç¨±**ï¼šæ ¼å¼ã€ŒXXXï¼ˆYYYï¼‰ã€ï¼Œå¦‚ã€Œç¿åœ‹å€«ï¼ˆWallace Wengï¼‰ã€
3. **æ˜ç¢ºè²¬ä»»æ­¸å±¬**ï¼šã€Œç”±XXXè² è²¬YYYã€
4. **å…·é«”æ™‚ç¨‹**ï¼šã€ŒXæœˆXæ—¥å‰å®Œæˆã€ï¼Œä¸ç”¨ã€Œè¿‘æœŸã€ã€Œå³å°‡ã€ç­‰æ¨¡ç³Šè©
5. **æ±ºç­–é‚è¼¯**ï¼šå¦‚æœæ‘˜è¦æåˆ°è¨è«–éç¨‹ï¼Œç°¡è¿°ã€Œå› ...æ‰€ä»¥...ã€
6. **å–®ä½å…¨å**ï¼šã€ŒåŒ—å¸‚æ•™è‚²å±€ã€ä¸ç¸®å¯«ç‚ºã€ŒåŒ—æ•™å±€ã€

ã€æ ¼å¼ã€‘ï¼š
ä½¿ç”¨ Markdown æ¢åˆ—å¼ï¼ˆ*ã€-ï¼‰ï¼Œåˆ†å±¤æ¸…æ™°ã€‚

ã€ç¦æ­¢ã€‘ï¼š
- ä¸è¦æ·»åŠ åŸæ–‡æ²’æœ‰çš„å…§å®¹
- ä¸è¦ä½¿ç”¨ã€Œç­‰ã€ã€Œç´„ã€ç­‰æ¨¡ç³Šè©ï¼ˆé™¤éåŸæ–‡å°±æ˜¯æ¨¡ç³Šï¼‰
- ä¸è¦æ”¹å¯«æ•¸å­—ï¼ˆã€Œ327è¬ã€ä¸è¦å¯«æˆã€Œä¸‰ç™¾å¤šè¬ã€ï¼‰
"""
```

#### å„ªåŒ– user prompt (pipeline_meeting_report.py:101-103):

**åŸç‰ˆæœ¬ï¼ˆåªæœ‰ summaryï¼‰**:
```python
prompt_init = "ä»¥ä¸‹ç‚ºæœ¬ä¸»é¡Œå‰ {} é …æ‘˜è¦ï¼š\n".format(len(list_init)) + \
              '\n'.join(f"- {s}" for s in list_init) + \
              "\nè«‹æ ¹æ“šä¸Šè¿°æ‘˜è¦æ’°å¯« Markdown æ¢åˆ—æœƒè­°å ±å‘Šç¯€é¸ã€‚"
```

**å„ªåŒ–ç‰ˆæœ¬ï¼ˆåŠ å…¥ structured_infoï¼‰**:
```python
prompt_init = f"ä»¥ä¸‹ç‚ºæœ¬ä¸»é¡Œå‰ {len(list_init)} é …å…§å®¹ï¼š\n\n"

for idx, row in init.iterrows():
    prompt_init += f"### [{row['chunk_id']}] {row['topic']}\n"
    prompt_init += f"**æ‘˜è¦**: {row['summary']}\n"

    # å¦‚æœæœ‰çµæ§‹åŒ–è³‡è¨Š
    if 'structured_info' in row and row['structured_info']:
        info = json.loads(row['structured_info'])
        if info.get('é‡‘é¡'):
            prompt_init += f"**é‡‘é¡**: {', '.join(info['é‡‘é¡'])}\n"
        if info.get('äººå'):
            prompt_init += f"**ç›¸é—œäººå“¡**: {', '.join(info['äººå'])}\n"
        if info.get('æ±ºç­–'):
            prompt_init += f"**æ±ºç­–äº‹é …**: {', '.join(info['æ±ºç­–'])}\n"

    # é—œéµï¼šé™„ä¸ŠåŸæ–‡ç‰‡æ®µï¼ˆå‰ 500å­—ï¼‰
    if 'text' in row:
        snippet = row['text'][:500] + "..." if len(row['text']) > 500 else row['text']
        prompt_init += f"**åŸæ–‡åƒè€ƒ**: {snippet}\n"

    prompt_init += "\n---\n\n"

prompt_init += """
è«‹æ•´åˆä¸Šè¿°å…§å®¹ï¼Œæ’°å¯«æœ¬ä¸»é¡Œçš„ Markdown å ±å‘Šã€‚
è¦æ±‚ï¼š
1. æ‰€æœ‰æ•¸å­—ç›´æ¥å¼•ç”¨
2. äººåç”¨ã€ŒXXXï¼ˆè‹±æ–‡åï¼‰ã€æ ¼å¼
3. æ±ºç­–äº‹é …ç¨ç«‹åˆ—å‡º
4. ä¿æŒæ¢åˆ—æ¸…æ™°
"""
```

**æ”¹é€²é»**:
- âœ… æ¯å€‹ chunk åŒ…å«ï¼šæ‘˜è¦ + çµæ§‹åŒ–info + åŸæ–‡ç‰‡æ®µ
- âœ… Gemma3 å¯ä»¥ã€Œå°ç…§ã€å¤šå€‹ä¾†æºï¼Œæé«˜æº–ç¢ºåº¦
- âœ… åŸæ–‡ç‰‡æ®µ 500å­—åœ¨ 2000å­—çª—å£å…§å¯å®¹ç´ 3-4å€‹ chunks

---

### ç­–ç•¥ 5: æ™ºèƒ½çºŒå¯«ç­–ç•¥æ”¹é€²

**å•é¡Œ**: ç¾åœ¨çºŒå¯«æ™‚åªçœ‹ã€Œå‰æ–‡15è¡Œ + æ–°æ‘˜è¦ã€

**å„ªåŒ–**: å¢åŠ ã€Œå‰æ–‡æ‘˜è¦ã€+ ã€Œé—œéµæ•¸å­—ç´¢å¼•ã€

**ä¿®æ”¹ pipeline_meeting_report.py:120-127**:

```python
# è®€å–æ•´ä»½å‰æ–‡ï¼Œç”Ÿæˆã€Œå‰æ–‡æ‘˜è¦ã€
with open(out_md, 'r', encoding='utf-8') as f:
    full_content = f.read()

# Step A: ç”Ÿæˆå‰æ–‡æ‘˜è¦ï¼ˆæ§åˆ¶åœ¨ 300å­—å…§ï¼‰
if len(full_content) > 1500:
    summary_prompt = f"""
ä»¥ä¸‹æ˜¯å‰æ–‡å…§å®¹çš„é–‹é ­èˆ‡çµå°¾ï¼š

ã€é–‹é ­ 500å­—ã€‘:
{full_content[:500]}

ã€çµå°¾ 500å­—ã€‘:
{full_content[-500:]}

è«‹ç”¨ 200-300å­— æ‘˜è¦å‰æ–‡å·²ç¶“è¨è«–çš„ä¸»è¦å…§å®¹ï¼š
- æ¶µè“‹å“ªäº›è­°é¡Œ
- æåˆ°å“ªäº›é—œéµæ•¸å­—
- æ¶‰åŠå“ªäº›äººå“¡
"""
    å‰æ–‡æ‘˜è¦ = ai_response([{"role": "user", "content": summary_prompt}], max_tokens=400)
else:
    å‰æ–‡æ‘˜è¦ = "ï¼ˆå‰æ–‡è¼ƒçŸ­ï¼Œè«‹ç›´æ¥åƒè€ƒä¸‹æ–¹å…§å®¹ï¼‰"

# Step B: æå–å‰æ–‡æœ€å¾Œ 15 è¡Œ
lines = full_content.split('\n')
context_lines = lines[-15:] if len(lines) >= 15 else lines

# Step C: æ§‹å»ºçºŒå¯« prompt
user_cont = f"""
ã€å‰æ–‡æ‘˜è¦ã€‘ï¼ˆä¾›åƒè€ƒï¼Œäº†è§£å·²è¨è«–å…§å®¹ï¼‰:
{å‰æ–‡æ‘˜è¦}

ã€å‰æ–‡æœ€å¾Œ15è¡Œã€‘ï¼ˆä¾›éŠœæ¥ï¼‰:
{''.join(context_lines)}

---

ã€æ–°çš„æœƒè­°ç‰‡æ®µã€‘:
"""

# åŠ å…¥æ–° chunks çš„å®Œæ•´è³‡è¨Š
for _, row in chunk.iterrows():
    user_cont += f"\n[{row['chunk_id']}] {row['summary']}\n"
    if 'structured_info' in row:
        user_cont += f"é—œéµè³‡è¨Š: {row['structured_info']}\n"
    if 'text' in row:
        user_cont += f"åŸæ–‡åƒè€ƒ: {row['text'][:400]}...\n"
    user_cont += "---\n"

user_cont += """
è«‹çºŒå¯«å ±å‘Šï¼Œè¦æ±‚ï¼š
1. è‡ªç„¶éŠœæ¥å‰æ–‡æœ€å¾Œ15è¡Œ
2. æ•´åˆæ–°ç‰‡æ®µçš„æ‰€æœ‰é—œéµè³‡è¨Š
3. ä¿æŒæ•¸å­—èˆ‡äººåæº–ç¢º
4. è¼¸å‡ºå®Œæ•´çš„ã€Œä¿®æ”¹å¾Œçš„æœ€å¾Œ15è¡Œ + æ–°å¢å…§å®¹ã€
"""
```

**æ”¹é€²é»**:
- âœ… ã€Œå‰æ–‡æ‘˜è¦ã€è®“ AI äº†è§£å…¨å±€
- âœ… ã€Œæœ€å¾Œ15è¡Œã€ä¿è­‰éŠœæ¥è‡ªç„¶
- âœ… ã€Œæ–°ç‰‡æ®µã€åŒ…å« summary + structured_info + text
- âœ… ç¸½è¼¸å…¥ç´„ 1800-2000å­—ï¼Œç¬¦åˆ Gemma3 çª—å£

---

### ç­–ç•¥ 6: å¾Œè™•ç†å“è³ªæª¢æŸ¥ï¼ˆæ–°å¢æ­¥é©Ÿ 5.5ï¼‰

**å‰µå»ºæ–°æ–‡ä»¶ `5.5quality_check.py`**:

åœ¨æ¯å€‹ topic MD ç”Ÿæˆå¾Œï¼ŒåŸ·è¡Œå“è³ªæª¢æŸ¥ï¼š

```python
def quality_check(md_file: Path, original_csv: Path) -> dict:
    """
    æª¢æŸ¥ç”Ÿæˆçš„ MD æ˜¯å¦éºå¤±é—œéµè³‡è¨Š
    """

    # è®€å– MD
    with open(md_file, 'r') as f:
        md_content = f.read()

    # è®€å–è©² topic çš„åŸå§‹è³‡æ–™
    df = pd.read_csv(original_csv)
    topic_name = md_file.stem
    topic_data = df[df['cluster_name'] == topic_name]

    # æå–æ‰€æœ‰æ‡‰è©²å‡ºç¾çš„é—œéµè³‡è¨Š
    all_amounts = []
    all_persons = []
    all_dates = []

    for _, row in topic_data.iterrows():
        if 'structured_info' in row:
            info = json.loads(row['structured_info'])
            all_amounts.extend(info.get('é‡‘é¡', []))
            all_persons.extend(info.get('äººå', []))
            all_dates.extend(info.get('æ—¥æœŸ', []))

    # æª¢æŸ¥ MD ä¸­æ˜¯å¦åŒ…å«
    missing_amounts = [a for a in set(all_amounts) if a not in md_content]
    missing_persons = [p for p in set(all_persons) if p not in md_content]
    missing_dates = [d for d in set(all_dates) if d not in md_content]

    report = {
        'file': str(md_file),
        'missing_amounts': missing_amounts,
        'missing_persons': missing_persons,
        'missing_dates': missing_dates,
        'completeness_score': calculate_score(missing_amounts, missing_persons, missing_dates)
    }

    # å¦‚æœå®Œæ•´åº¦ < 85%ï¼Œè¨˜éŒ„è­¦å‘Š
    if report['completeness_score'] < 0.85:
        print(f"âš ï¸ {md_file.name} å®Œæ•´åº¦åƒ… {report['completeness_score']*100:.1f}%")
        print(f"  ç¼ºå¤±é‡‘é¡: {missing_amounts}")
        print(f"  ç¼ºå¤±äººå: {missing_persons}")

    return report
```

**æ•´åˆé€² pipeline**:
```python
# åœ¨ pipeline_meeting_report.py æœ€å¾Œ
quality_reports = []
for topic_md in glob.glob(os.path.join(args.output, "*.md")):
    report = quality_check(Path(topic_md), args.csv)
    quality_reports.append(report)

# è¼¸å‡ºå“è³ªå ±å‘Š
with open(os.path.join(args.output, 'quality_report.json'), 'w') as f:
    json.dump(quality_reports, f, ensure_ascii=False, indent=2)
```

---

### ç­–ç•¥ 7: Gemma3 Prompt å·¥ç¨‹å„ªåŒ–

**é‡å° Gemma3 27B çš„ç‰¹æ€§èª¿æ•´**:

#### ç‰¹æ€§ 1: Gemma3 å°ã€Œçµæ§‹åŒ–è¼¸å‡ºã€è¡¨ç¾å¥½

**åˆ©ç”¨æ–¹å¼**: åœ¨æ‰€æœ‰ prompt ä¸­ä½¿ç”¨æ˜ç¢ºçš„çµæ§‹æ¨™è¨˜

```python
# âŒ ä¸å¥½ï¼ˆæ¨¡ç³Šï¼‰
"è«‹æ‘˜è¦ä»¥ä¸‹å…§å®¹ï¼ŒåŒ…å«æ•¸å­—å’Œäººå"

# âœ… å¥½ï¼ˆçµæ§‹åŒ–ï¼‰
"""
è«‹æŒ‰ä»¥ä¸‹æ ¼å¼æ‘˜è¦ï¼š

ã€æ•¸å­—ã€‘: åˆ—å‡ºæ‰€æœ‰é‡‘é¡ã€æ•¸é‡
ã€äººå“¡ã€‘: åˆ—å‡ºæ‰€æœ‰æåˆ°çš„äººå
ã€æ±ºç­–ã€‘: åˆ—å‡ºæ±ºå®šäº‹é …
ã€æ™‚ç¨‹ã€‘: åˆ—å‡ºæ—¥æœŸèˆ‡æˆªæ­¢æ—¥
"""
```

#### ç‰¹æ€§ 2: Gemma3 å°ã€Œä¸­æ–‡æ¢åˆ—ã€ç†è§£å¥½

**åˆ©ç”¨æ–¹å¼**: è¼¸å…¥èˆ‡è¼¸å‡ºéƒ½ä½¿ç”¨æ¢åˆ—

```python
user_prompt = """
ä»¥ä¸‹æ˜¯ä¸‰å€‹æœƒè­°ç‰‡æ®µï¼š

1. ç‰‡æ®µ[01]ï¼š
   - æ‘˜è¦ï¼šXXX
   - é‡‘é¡ï¼šYYY
   - æ±ºç­–ï¼šZZZ

2. ç‰‡æ®µ[02]ï¼š
   ...

è«‹æ•´åˆç‚ºå ±å‘Šï¼Œæ ¼å¼ï¼š
* è²¡å‹™ç‹€æ³ï¼š
  * é‡‘é¡Aï¼šXXXè¬
  * é‡‘é¡Bï¼šYYYè¬
* æ±ºç­–äº‹é …ï¼š
  * ç”±AAAè² è²¬BBB
"""
```

#### ç‰¹æ€§ 3: Gemma3 å°ã€Œfew-shotã€æ•ˆæœé¡¯è‘—

**åˆ©ç”¨æ–¹å¼**: åœ¨ system prompt åŠ å…¥ç¯„ä¾‹

```python
SYSTEM_PROMPT_INIT = """
ä½ æ˜¯æœƒè­°è¨˜éŒ„å°ˆå®¶ã€‚ä»¥ä¸‹æ˜¯ä½ æ‡‰è©²ç”¢å‡ºçš„æ ¼å¼ç¯„ä¾‹ï¼š

ã€ç¯„ä¾‹è¼¸å…¥ã€‘:
æ‘˜è¦1: è”¡å®—å“²å ±å‘Šåˆ‘äº‹å±€æ¡ˆ327è¬å»¶é²2å€‹æœˆï¼Œç¿åœ‹å€«è² è²¬è¿½è¹¤
æ‘˜è¦2: åŒ—å¸‚æ•™è‚²å±€å°¾æ¬¾13è¬ç­‰å¾…è“‹ç« 

ã€ç¯„ä¾‹è¼¸å‡ºã€‘:
## è²¡å‹™è¿½è¹¤

### å»¶é²æ¬¾é …
* **è¡›ç¦éƒ¨ç¬¬2æœŸæ¬¾**
  * é‡‘é¡ï¼š327è¬
  * å»¶é²ï¼š2å€‹æœˆï¼ˆè‡ª8æœˆ13æ—¥ï¼‰
  * è²¬ä»»äººï¼šç¿åœ‹å€«ï¼ˆWallace Wengï¼‰è² è²¬è¿½è¹¤è¡Œæ”¿ç¨‹åº

* **åŒ—å¸‚æ•™è‚²å±€å°¾æ¬¾**
  * é‡‘é¡ï¼š13è¬
  * ç‹€æ…‹ï¼šåƒ…å¾…è“‹ç« 
  * è²¬ä»»äººï¼šç¿åœ‹å€«è¿½è¹¤

---

ç¾åœ¨è«‹æŒ‰æ­¤æ ¼å¼è™•ç†å¯¦éš›å…§å®¹ã€‚
"""
```

---

## ğŸ“ˆ é æœŸæ•ˆæœèˆ‡æˆæœ¬

### æ•ˆæœé ä¼°

| å„ªåŒ–é …ç›® | é æœŸæå‡ | é›£åº¦ | å„ªå…ˆç´š |
|---------|---------|------|--------|
| **ç­–ç•¥1: ä¿ç•™ text æ¬„ä½** | +8åˆ† (86â†’94) | ğŸŸ¢ ç°¡å–® | â­â­â­â­â­ æœ€é«˜ |
| **ç­–ç•¥2: æ”¹é€²æ‘˜è¦Prompt** | +4åˆ† (86â†’90) | ğŸŸ¢ ç°¡å–® | â­â­â­â­â­ æœ€é«˜ |
| ç­–ç•¥3: çµæ§‹åŒ–æå– | +3åˆ† (86â†’89) | ğŸŸ¡ ä¸­ç­‰ | â­â­â­â­ é«˜ |
| ç­–ç•¥4: æ”¹é€²ç”ŸæˆPrompt | +3åˆ† (86â†’89) | ğŸŸ¢ ç°¡å–® | â­â­â­â­ é«˜ |
| ç­–ç•¥5: æ™ºèƒ½çºŒå¯« | +2åˆ† (86â†’88) | ğŸŸ¡ ä¸­ç­‰ | â­â­â­ ä¸­ |
| ç­–ç•¥6: å“è³ªæª¢æŸ¥ | +1åˆ† (æä¾›åé¥‹) | ğŸŸ¢ ç°¡å–® | â­â­â­ ä¸­ |
| ç­–ç•¥7: Promptå·¥ç¨‹ | +2åˆ† (86â†’88) | ğŸŸ¢ ç°¡å–® | â­â­â­â­ é«˜ |

**ç¶œåˆå¯¦æ–½ (ç­–ç•¥1+2+4)**: é æœŸå¾ **86åˆ† â†’ 94åˆ†**

### æˆæœ¬åˆ†æ

| é …ç›® | ç¾åœ¨ | å„ªåŒ–å¾Œ | è®ŠåŒ– |
|-----|------|--------|------|
| APIèª¿ç”¨æ¬¡æ•¸ | ~150æ¬¡ | ~180æ¬¡ | +20% |
| æ¯æ¬¡tokenæ•¸ | ~500 | ~800 | +60% |
| ç¸½è™•ç†æ™‚é–“ | 19.2åˆ†é˜ | 25-28åˆ†é˜ | +30-45% |
| **ç¸½æˆæœ¬** | $0.80 | $1.20 | +50% |
| **å“è³ªåˆ†æ•¸** | 86åˆ† | 94åˆ† | +9.3% |
| **ROI** | åŸºæº– | **æˆæœ¬å¢50%ï¼Œå“è³ªå¢9%** | å€¼å¾— |

---

## ğŸš€ å¯¦æ–½è¨ˆåŠƒ

### Phase 1: å¿«é€Ÿå„ªåŒ–ï¼ˆæœ¬é€±ï¼‰

**å„ªå…ˆå¯¦æ–½ç­–ç•¥ 1 + 2**ï¼ˆæœ€é«˜ROIï¼‰

#### Step 1.1: ä¿®æ”¹ 3brief_summary_reindex.py
```bash
# å‚™ä»½åŸæª”
cp 3brief_summary_reindex.py 3brief_summary_reindex.py.backup

# ä¿®æ”¹ç¬¬25è¡Œï¼šä¿ç•™ text æ¬„ä½
# åŸï¼šdf = df[['chunk_id', 'summary']]
# æ”¹ï¼šdf = df[['chunk_id', 'summary', 'text']]
```

#### Step 1.2: ä¿®æ”¹ 2chunks_summary.py
```bash
# å‚™ä»½
cp 2chunks_summary.py 2chunks_summary.py.backup

# ä¿®æ”¹ç¬¬60è¡Œçš„ promptï¼ˆä½¿ç”¨å„ªåŒ–ç‰ˆæœ¬Aï¼‰
# å­—æ•¸é™åˆ¶æ”¹ç‚º 150
# å¢åŠ  6 å¤§è¦ç´ è¦æ±‚
```

#### Step 1.3: æ¸¬è©¦
```bash
# é‡æ–°é‹è¡Œ pipeline
python main.py /home/henry/AuMeet_package/æœƒè­°BSS/BSS.txt

# å°æ¯”æ–°èˆŠç‰ˆæœ¬
python compare_reports.py \
  --old /home/henry/AuMeet_package/æœƒè­°BSS/topic_report_clean_dedup.md \
  --new /home/henry/AuMeet_package/æœƒè­°BSS/topic_report_clean_dedup_v2.md \
  --metrics completeness,accuracy
```

**é æœŸ**: Phase 1 å®Œæˆå¾Œï¼Œåˆ†æ•¸å¾ **86 â†’ 91åˆ†**

### Phase 2: ä¸­ç­‰å„ªåŒ–ï¼ˆä¸‹é€±ï¼‰

å¯¦æ–½ç­–ç•¥ 3 + 4

#### Step 2.1: å‰µå»º 2.5extract_key_info.py
```bash
# æ–°å¢æ–‡ä»¶
vi 2.5extract_key_info.py
# ï¼ˆå¯¦ç¾çµæ§‹åŒ–è³‡è¨Šæå–ï¼‰

# æ•´åˆé€² main.py
```

#### Step 2.2: ä¿®æ”¹ pipeline_meeting_report.py
```bash
# æ›´æ–° SYSTEM_PROMPT_INIT å’Œ SYSTEM_PROMPT_CONT
# æ›´æ–° user prompt æ§‹å»ºé‚è¼¯
# åŠ å…¥ structured_info å’Œ text ç‰‡æ®µ
```

**é æœŸ**: Phase 2 å®Œæˆå¾Œï¼Œåˆ†æ•¸å¾ **91 â†’ 94åˆ†**

### Phase 3: å®Œå–„å„ªåŒ–ï¼ˆä¸‹ä¸‹é€±ï¼‰

å¯¦æ–½ç­–ç•¥ 5 + 6 + 7

---

## ğŸ¯ é—œéµæˆåŠŸæŒ‡æ¨™ (KPI)

### æ•¸å­—æº–ç¢ºåº¦
- **ç›®æ¨™**: 25é …é—œéµæ•¸å­— â†’ 24/25 (96%)
- **ç¾ç‹€**: 19/25 (76%)
- **ç­–ç•¥**: ä¿ç•™ text + æ”¹é€² prompt

### æ±ºç­–å®Œæ•´åº¦
- **ç›®æ¨™**: 15é …æ±ºç­–äº‹é … â†’ 14/15 (93%)
- **ç¾ç‹€**: 12/15 (80%)
- **ç­–ç•¥**: æ‘˜è¦åŠ å…¥ã€Œæ±ºç­–ã€è¦ç´  + çºŒå¯«åŒ…å«åŸæ–‡

### éŒ¯èª¤ç‡
- **ç›®æ¨™**: é›¶é‡å¤§éŒ¯èª¤ï¼ˆå¦‚ã€Œè¼ªæ¤…ä¸»å¸­ã€ï¼‰
- **ç­–ç•¥**: çµæ§‹åŒ–æå– + å“è³ªæª¢æŸ¥

### è™•ç†æ•ˆç‡
- **ç›®æ¨™**: ç¸½æ™‚é–“ â‰¤ 30åˆ†é˜
- **ç¾ç‹€**: 19.2åˆ†é˜
- **å®¹è¨±**: +50% (28.8åˆ†é˜)

---

## ğŸ’» å…·é«”ä»£ç¢¼ç¤ºä¾‹

### å®Œæ•´ä¿®æ”¹çš„ 2chunks_summary.py (é—œéµéƒ¨åˆ†)

```python
def generate_summary_tags_natural(text):
    # æ–°çš„ promptï¼ˆå„ªåŒ–ç‰ˆæœ¬ Aï¼‰
    prompt = f"""é€å­—ç¨¿ç‰‡æ®µå…§å®¹å¦‚ä¸‹ï¼š
{text}

ä½ æ˜¯å°ˆæ¥­æœƒè­°è¨˜éŒ„AIï¼Œè«‹ç”¨ 120-150å­— æ‘˜è¦æ­¤ç‰‡æ®µï¼Œå¿…é ˆåŒ…å«ï¼š

ã€å¿…é ˆåŒ…å«ã€‘ï¼š
1. **æ•¸å­—èˆ‡é‡‘é¡**ï¼šæ‰€æœ‰æåˆ°çš„é‡‘é¡ã€ç™¾åˆ†æ¯”ã€æ•¸é‡ï¼ˆç²¾ç¢ºåˆ°å€‹ä½ï¼‰
2. **äººåèˆ‡è·ç¨±**ï¼šå®Œæ•´çš„ä¸­è‹±æ–‡å§“åèˆ‡è·ä½
3. **æ±ºç­–äº‹é …**ï¼šèª°æ±ºå®šäº†ä»€éº¼ã€èª°è² è²¬åŸ·è¡Œã€ä½•æ™‚å®Œæˆ
4. **æ™‚ç¨‹æ—¥æœŸ**ï¼šå…·é«”çš„æ—¥æœŸã€æœˆä»½ã€å¹´ä»½
5. **å–®ä½åç¨±**ï¼šå®Œæ•´çš„æ©Ÿé—œã€å…¬å¸ã€éƒ¨é–€åç¨±ï¼ˆä¸ç¸®å¯«ï¼‰
6. **è¨è«–éç¨‹**ï¼šå¦‚æœæœ‰çˆ­è­°æˆ–è§£æ±ºæ–¹æ¡ˆï¼Œç°¡è¿°é‚è¼¯

ã€æ ¼å¼è¦æ±‚ã€‘ï¼š
- ä½¿ç”¨æ¢åˆ—å¼ï¼ˆæ¯è¡Œä¸€å€‹é‡é»ï¼‰
- æ•¸å­—ç”¨é˜¿æ‹‰ä¼¯æ•¸å­—
- äººåæ ¼å¼ï¼šã€ŒXXXï¼ˆYYYï¼‰ã€å¦‚ã€Œç¿åœ‹å€«ï¼ˆWallaceï¼‰ã€
- æ±ºç­–æ ¼å¼ï¼šã€Œæ±ºå®š/æ±ºè­°ï¼šç”±XXXè² è²¬YYYï¼ŒZZæœˆå®Œæˆã€

ã€ç¯„ä¾‹ã€‘ï¼š
è¼¸å…¥ï¼šè”¡å®—å“²è©¢å•ç¿åœ‹å€«é—œæ–¼åœ‹å®¶æ°´æ¡ˆé€²åº¦ï¼Œç¢ºèªè©²æ¡ˆé è¨ˆè½åœ¨æ˜å¹´...
è¼¸å‡ºï¼š
- è­°é¡Œï¼šåœ‹å®¶æ°´æ¡ˆé€²åº¦ç¢ºèª
- è©¢å•äººï¼šè”¡å®—å“²ï¼ˆTom Tsaiï¼‰
- å›ç­”äººï¼šç¿åœ‹å€«ï¼ˆWallace Wengï¼‰
- æ™‚ç¨‹ï¼šé è¨ˆæ˜å¹´å®Œæˆ
- æ¶‰åŠå–®ä½ï¼šæ°¸è±

ç¾åœ¨è«‹æ‘˜è¦ä¸Šè¿°é€å­—ç¨¿ï¼š
"""

    if len(text) > MAX_CHARS:
        print(f"âš ï¸ è¶…å‡ºå­—æ•¸é™åˆ¶ï¼ˆ{len(text)}å­—ï¼‰ï¼Œå–å‰{MAX_CHARS}å­—", file=sys.stderr)
        text = text[:MAX_CHARS]

    messages = [{"role": "user", "content": prompt}]
    return ai_response(messages, max_tokens=250)  # å¢åŠ  max_tokens
```

### å®Œæ•´ä¿®æ”¹çš„ 3brief_summary_reindex.py

```python
def run(input_CSV: str) -> pathlib.Path:
    # è®€å– CSV
    df = pd.read_csv(
        input_CSV,
        skip_blank_lines=True,
        quotechar='"',
        quoting=0,
        escapechar='\\',
        on_bad_lines='skip'
    )

    # æ¸…ç† summary
    if 'summary' in df.columns:
        df['summary'] = df['summary'].astype(str).apply(
            lambda x: ' '.join(x.split())
        )
        df['chunk_id'] = range(1, len(df) + 1)

    # â˜…â˜…â˜… é—œéµä¿®æ”¹ï¼šä¿ç•™ text æ¬„ä½ â˜…â˜…â˜…
    if 'text' in df.columns:
        df = df[['chunk_id', 'summary', 'text']]
    else:
        print("âš ï¸ è­¦å‘Šï¼šæ²’æœ‰ text æ¬„ä½ï¼Œå°‡å½±éŸ¿å¾ŒçºŒå“è³ª", file=sys.stderr)
        df = df[['chunk_id', 'summary']]

    # è¼¸å‡ºè·¯å¾‘
    input_dir = os.path.dirname(input_CSV)
    input_file = os.path.basename(input_CSV)
    filename_wo_ext = os.path.splitext(input_file)[0]
    output_dir = os.path.join(input_dir, f"{filename_wo_ext}_output")
    os.makedirs(output_dir, exist_ok=True)

    output_path = os.path.join(output_dir, f"{filename_wo_ext}_reindexed.csv")

    # å„²å­˜
    df.to_csv(output_path, index=False)
    print(f"âœ… Saved: {output_path}", file=sys.stderr)
    print(f"ğŸ“Š ä¿ç•™æ¬„ä½: {df.columns.tolist()}", file=sys.stderr)

    return pathlib.Path(output_path)
```

---

## ğŸ”„ A/Bæ¸¬è©¦æ–¹æ¡ˆ

ç‚ºäº†å®¢è§€è©•ä¼°ï¼Œå»ºè­°é€²è¡Œ A/B æ¸¬è©¦ï¼š

### æ¸¬è©¦è¨­è¨ˆ

**å°ç…§çµ„ (A)**: ç¾æœ‰ pipelineï¼ˆä¸ä¿®æ”¹ï¼‰
**å¯¦é©—çµ„ (B)**: å„ªåŒ–å¾Œ pipelineï¼ˆPhase 1 ä¿®æ”¹ï¼‰

**æ¸¬è©¦æ¨£æœ¬**: 3å ´ä¸åŒé¡å‹çš„æœƒè­°
1. BSS ç¶“ç‡Ÿç®¡ç†æœƒè­°ï¼ˆå·²æœ‰ï¼‰
2. æŠ€è¡“è¨è«–æœƒè­°ï¼ˆåæŠ€è¡“ç´°ç¯€ï¼‰
3. è²¡å‹™å¯©æŸ¥æœƒè­°ï¼ˆæ•¸å­—å¯†é›†ï¼‰

### è©•ä¼°æŒ‡æ¨™

```python
# è©•ä¼°è…³æœ¬ evaluate.py
def evaluate_report(generated_report, ground_truth_claude):
    metrics = {
        'æ•¸å­—æº–ç¢ºç‡': check_numbers_accuracy(generated, truth),
        'äººåå®Œæ•´åº¦': check_person_names(generated, truth),
        'æ±ºç­–å®Œæ•´åº¦': check_decisions(generated, truth),
        'æ™‚ç¨‹æº–ç¢ºç‡': check_dates(generated, truth),
        'éŒ¯èª¤ç‡': count_errors(generated, truth),
        'å¯è®€æ€§åˆ†æ•¸': readability_score(generated)
    }
    return metrics
```

**åˆ¤å®šæ¨™æº–**:
- è‹¥å¯¦é©—çµ„(B)å„é …æŒ‡æ¨™å¹³å‡ **+5%** â†’ æ­£å¼æ¡ç”¨
- è‹¥æˆæœ¬å¢åŠ  > æ•ˆæœæå‡ â†’ èª¿æ•´å„ªåŒ–ç­–ç•¥

---

## âš ï¸ é¢¨éšªèˆ‡æ‡‰å°

### é¢¨éšª 1: Gemma3 çª—å£ä»ç„¶ä¸è¶³

**ç—‡ç‹€**: å³ä½¿ä¿ç•™ textï¼ŒçºŒå¯«æ™‚ä»è¶…é 2000å­—
**æ‡‰å°**:
- æ–¹æ¡ˆA: å‹•æ…‹èª¿æ•´åŒ…å«çš„ text ç‰‡æ®µé•·åº¦
- æ–¹æ¡ˆB: åªåœ¨ã€Œåˆå§‹ç”Ÿæˆã€ç”¨å®Œæ•´ textï¼ŒçºŒå¯«æ™‚ç”¨ summary + structured_info

### é¢¨éšª 2: è™•ç†æ™‚é–“éé•·

**ç—‡ç‹€**: Phase 2 å¯¦æ–½å¾Œè¶…é 30åˆ†é˜
**æ‡‰å°**:
- ç­–ç•¥3ï¼ˆçµæ§‹åŒ–æå–ï¼‰è¨­ç‚ºã€Œå¯é¸ã€
- åªå°ã€Œé—œéµ chunksã€ï¼ˆå«é‡‘é¡ã€æ±ºç­–ï¼‰åšçµæ§‹åŒ–æå–

### é¢¨éšª 3: Gemma3 ç”Ÿæˆå“è³ªä¸ç©©å®š

**ç—‡ç‹€**: æœ‰æ™‚ç”Ÿæˆå¥½ï¼Œæœ‰æ™‚å·®
**æ‡‰å°**:
- é™ä½ temperatureï¼ˆå¾ 0.3 â†’ 0.1ï¼‰
- å¢åŠ  few-shot ç¯„ä¾‹
- å¯¦æ–½ã€Œretryæ©Ÿåˆ¶ã€ï¼šè‹¥å“è³ªæª¢æŸ¥æœªé€šéï¼Œé‡æ–°ç”Ÿæˆ

---

## ğŸ“ ç¸½çµ

### æœ€é‡è¦çš„3å€‹æ”¹é€²ï¼ˆç«‹å³å¯¦æ–½ï¼‰

1. **ä¿ç•™ text æ¬„ä½** (3brief_summary_reindex.py)
   - å·¥ä½œé‡ï¼š5åˆ†é˜
   - æ•ˆæœï¼š+8åˆ†

2. **æ”¹é€²æ‘˜è¦ Prompt** (2chunks_summary.py)
   - å·¥ä½œé‡ï¼š15åˆ†é˜
   - æ•ˆæœï¼š+4åˆ†

3. **æ”¹é€²ç”Ÿæˆ Prompt** (pipeline_meeting_report.py)
   - å·¥ä½œé‡ï¼š30åˆ†é˜
   - æ•ˆæœï¼š+3åˆ†

**ç¸½è¨ˆ**: 50åˆ†é˜å·¥ä½œé‡ï¼Œé æœŸ **86åˆ† â†’ 95åˆ†**ï¼ˆ+10.5%ï¼‰

### è‡´å‹é—œéµ

åœ¨ **Gemma3 2000å­—çª—å£** é™åˆ¶ä¸‹ï¼Œè¦æ¥è¿‘ Claude ç‰ˆå“è³ªï¼Œæ ¸å¿ƒç­–ç•¥æ˜¯ï¼š

> **ä¸è¦è©¦åœ–è®“ Gemma3 ä¸€æ¬¡çœ‹å®Œæ‰€æœ‰å…§å®¹ï¼Œè€Œæ˜¯çµ¦å®ƒã€Œå¤šå±¤æ¬¡ã€çµæ§‹åŒ–ã€çš„è³‡è¨Šï¼š**
> 1. Summaryï¼ˆæ‘˜è¦å±¤ï¼‰
> 2. Structured Infoï¼ˆé—œéµè³‡è¨Šå±¤ï¼‰
> 3. Text Snippetï¼ˆåŸæ–‡è­‰æ“šå±¤ï¼‰
>
> **è®“ Gemma3 å¯ä»¥ã€Œäº¤å‰é©—è­‰ã€ï¼Œè€Œä¸æ˜¯ã€Œæ¨æ¸¬ã€ã€‚**

é€™å°±æ˜¯ç‚ºä»€éº¼ä¿ç•™ `text` æ¬„ä½ + æ”¹é€² prompt å¯ä»¥å¸¶ä¾†æœ€å¤§æ•ˆæœã€‚

---

**ä¸‹ä¸€æ­¥è¡Œå‹•**: è¦æˆ‘ç¾åœ¨ç«‹å³å¯¦æ–½ Phase 1 çš„ä¿®æ”¹å—ï¼Ÿæˆ‘å¯ä»¥ç›´æ¥å¹«ä½ æ”¹å¥½ 2 å’Œ 3 çš„ç¨‹å¼ç¢¼ã€‚

