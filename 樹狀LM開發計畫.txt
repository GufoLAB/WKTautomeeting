# 📘 本地版 NotebookLM 架構開發文件

## 🎯 專案目標

建立一個在本地端運行、具備語義查詢與多層摘要能力的知識系統，模仿 Google NotebookLM 的使用體驗。此系統需支援以下能力：

- 處理超長逐字稿（超過模型最大上下文）
- 切分段落後為每段建立摘要與主題標籤
- 支援主題聚類與遞迴合併（知識樹）
- 建立向量索引資料庫，供語義查詢使用
- 最終回傳多段相關內容並用本地大模型回答查詢

---

## 🧱 架構流程

### 一、前處理階段

#### A. 切段處理（已完成）
- 使用 AI 模型或傳統斷點演算法（如 cosine、TextTiling）將逐字稿切成約 100 個語意段落（chunks）
- 每個 chunk 約 100~300 字，儘量保持語義完整

#### B. 多層摘要與標籤生成
- 每段 chunk 使用大模型生成：
  - 精簡摘要（約 100 字）：供查詢向量比對使用
  - 主題摘要（約 200 字）：供主題聚類或展示
  - 主題標籤（tags）：供分類與群聚

```json
{
  "chunk_id": "chunk_012",
  "summary": "圖書館人力因經費削減不足，影響營運時數。",
  "tags": ["圖書館", "經費問題", "人力不足"],
  "original": "（逐字稿段落原文）"
}
```

---

### 二、主題聚類（可選強化）

#### A. 分批聚類處理
- 將摘要分批（每批 10~15 條，避免超過 1000 字）丟入大模型進行主題分類
- 輸出該批主題與 chunk 對應表

#### B. 遞迴合併（如需建樹狀架構）
- 對多批主題進行高階合併（例如聚合成「經費問題」、「法規限制」等上位類別）

---

### 三、向量資料庫建構（必要）

#### A. 建立雙層資料庫（推薦）

| 層級     | 資料來源     | 用途             |
|----------|--------------|------------------|
| 摘要層   | 精簡摘要     | 查詢初步召回     |
| 原文層   | chunk 原文   | 組合回答細節內容 |

- 使用 all-MiniLM-L6-v2、bge-m3 等模型生成向量
- 使用 FAISS、Chroma 或其他儲存向量與索引

---

### 四、查詢處理流程

#### A. RAG 檢索流程
1. 將使用者輸入的問題轉為 query embedding
2. 在摘要層索引中查找 Top-K 相似 chunk
3. 根據 chunk ID 從原文層拉取對應 chunk
4. 組合問題與相關 chunk，丟入大模型回答

#### B. 建議 Prompt 格式

```
你是根據逐字稿回答問題的助理。以下是與問題最相關的紀錄片段，請依據內容忠實作答，不要編造。
問題：{user_question}

相關內容：
1. {chunk_text_1}
2. {chunk_text_2}
...

請根據以上資訊回答：
```

---

## ✅ 任務追蹤與代辦事項

| 項目 | 說明 | 狀態 |
|------|------|------|
| 初步 chunk 切割 | AI 或傳統演算法處理 | ✅ 已完成 |
| 多層摘要與 tag 產生 | 使用 27B 模型批次生成摘要與標籤 | ⏳ 進行中 |
| 向量庫建立（摘要層）| 建立摘要向量與索引 | ⏳ 尚未開始 |
| 向量庫建立（原文層）| 建立原文向量與索引 | ⏳ 尚未開始 |
| 主題聚類邏輯 | 進行分批聚合與主題分類 | 💤 可延後 |
| 查詢流程實作 | query → top-k → 模型回答 | ⏳ 尚未開始 |
| Prompt 模板設計 | 撰寫回覆提示詞範本 | ⏳ 尚未開始 |
| CLI 或 UI | 若需人機介面互動 | 💤 可延後 |

---

## 🔚 備註

- 本系統設計以部署在本地為優先，適合與 Gemma 27B / Mistral 7B 等大型模型搭配
- 若查詢需求不高，可考慮 embedding 預先儲存為 json + numpy 查詢，即可省略 DB
- 可逐步演進為 NotebookLM 式互動問答平台

