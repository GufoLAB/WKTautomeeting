import os
import re
import argparse
from openai import OpenAI
from dotenv import load_dotenv
from tqdm import tqdm

# åˆå§‹åŒ– GPT client
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# åƒæ•¸è¨­å®š
parser = argparse.ArgumentParser(description="ç”¨ GPT å°‡é€å­—ç¨¿ä¾ä¸»é¡Œåˆ†æ®µä¸¦è¼¸å‡º md æª”")
parser.add_argument("input_file", help="è¼¸å…¥é€å­—ç¨¿æª”æ¡ˆï¼ˆæ¯è¡Œæ ¼å¼ç‚º speakerX: èªªè©±å…§å®¹ï¼‰")
args = parser.parse_args()

input_file = args.input_file
MAX_TEXT_LEN = 3000
#æœ‰åˆ†å…©å€‹ï¼¡ï¼©ä¸€å€‹åˆ‡æ–·ä¸€å€‹å¯«çµè«– å¯ä»¥search modelä¿®æ”¹
#model_choice="gpt-3.5-turbo" 
model_choice="gpt-4o"


# è¼¸å‡ºè³‡æ–™å¤¾
output_dir = os.path.splitext(os.path.basename(input_file))[0] + "_topics"
os.makedirs(output_dir, exist_ok=True)


# è®€å…¥é€å­—ç¨¿
with open(input_file, "r", encoding="utf-8") as f:
    lines = [line.strip() for line in f if line.strip()]

# ğŸ” ä¸»é¡Œç”Ÿé•·å¼åˆ‡æ®µ
start = 0
topic_indices = [0]
step = 4
initial_len = 6

while start < len(lines):
    cur_len = initial_len
    while start + cur_len < len(lines):
        block = "\n".join(lines[start:start+cur_len])
        prompt = f"""ä»¥ä¸‹æ˜¯ä¸€æ®µé€å­—ç¨¿æ®µè½ã€‚è«‹åˆ¤æ–·é€™æ®µæ˜¯å¦ä»åœ¨æè¿°åŒä¸€å€‹è¨è«–ä¸»é¡Œã€‚
å¦‚æœä»æ˜¯åŒä¸€ä¸»é¡Œè«‹å›å‚³ Trueï¼Œè‹¥å·²ç¶“åŒ…å«æ–°ä¸»é¡Œå‰‡è«‹å›å‚³ Falseï¼š
---
{block}
---
å›ç­”ï¼š"""

        res = client.chat.completions.create(
            model=model_choice,
            messages=[{"role": "user", "content": prompt}]
        )
        reply = res.choices[0].message.content.strip().lower()
        if "false" in reply:
            break
        cur_len += step

    start += cur_len
    topic_indices.append(start)

# âœ… æ ¹æ“šåˆ‡é»åˆ‡æ®µï¼ŒåŠ å…¥ä¸Šä¸‹æ–‡ padding
padding = 2
topic_indices = sorted(set(topic_indices))
segments = []

for i in range(len(topic_indices)):
    seg_start = topic_indices[i]
    seg_end = topic_indices[i+1] if i+1 < len(topic_indices) else len(lines)

    real_start = max(0, seg_start - padding)
    real_end = min(len(lines), seg_end + padding)
    segments.append(lines[real_start:real_end])

# ğŸ”– æ¸…ç†éŒ¯èª¤å­—å…ƒ
def sanitize_filename(text):
    # ç§»é™¤æ‰€æœ‰ä¸åˆæ³•æª”åå­—å…ƒ
    text = re.sub(r'[\\/*?:"<>|ï¼ˆï¼‰()ã€ã€‘ã€Œã€ã€ï¼Œã€‚ï¼ï¼Ÿ~`\'\s]+', '_', text)
    # åƒ…ä¿ç•™ä¸­è‹±æ–‡èˆ‡æ•¸å­—ï¼ˆé¿å… emojiï¼‰
    text = re.sub(r'[^\w\u4e00-\u9fff]', '', text)
    # é™åˆ¶é•·åº¦
    return text[:20].strip("_")

# ğŸ“ å¯«å…¥æ¯æ®µï¼‹ä¸»é¡Œæ‘˜è¦
for i, segment in enumerate(tqdm(segments, desc="å¯«å…¥ä¸»é¡Œæ®µè½"), 1):
    text_block = "\n".join(segment)
    summary_input = text_block[:MAX_TEXT_LEN]

    summary_prompt = f"""è«‹å¯«å‡ºé€™ä¸€æ®µæœ€é‡è¦çš„äº‹æƒ…ï¼Œä¸€å­—ä¸æ¼ï¼Œä¸è¦åŠ æ¨™é»æˆ–è§£é‡‹ï¼š
---
{summary_input}
---
ä¸»é¡Œï¼š"""

    summary_res = client.chat.completions.create(
        model=model_choice,
        messages=[{"role": "user", "content": summary_prompt}]
    )
    topic_title = summary_res.choices[0].message.content.strip()
    filename_title = sanitize_filename(topic_title)
    filename = f"{i:02d}_{filename_title}.md"
    filepath = os.path.join(output_dir, filename)

    with open(filepath, "w", encoding="utf-8") as f:
        f.write(f"# {topic_title}\n\n")
        f.write(text_block)

    print(f"âœ… å¯«å…¥ï¼š{filename}")

print(f"\nğŸ‰ å…±åˆ‡å‡º {len(segments)} æ®µä¸»é¡Œï¼Œå„²å­˜åœ¨ï¼š{output_dir}")
