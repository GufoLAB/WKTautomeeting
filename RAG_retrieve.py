#python RAG_retrieve.py /home/henry/automeeting/æ°‘æ—å­¸è¡—è¨ª/é€å­—ç¨¿_ä¿®æ­£ç‰ˆ.txt
#python RAG_retrieve.py /home/henry/automeeting/2025Feb_NSTM_meet/shorten_topicsv2/chunks_summariesv3.jsonl
"""æ­£ç¢ºåšæ³•ï¼š
å‡è¨­ä½ æ˜¯é€™æ¨£å»ºçš„ï¼š

python RAG_Embedding.py /home/henry/automeeting/2025Feb_NSTM_meet/shorten_topicsv2/chunks_summariesv3.jsonl
é€™æœƒç”¢ç”Ÿ

/home/henry/automeeting/2025Feb_NSTM_meet/shorten_topicsv2/rag_embed_chunks_summariesv3
    â”œâ”€â”€ faiss.index
    â””â”€â”€ documents.txt
æŸ¥è©¢æ™‚è¦ç”¨ chunks_summariesv3.jsonl ä½œç‚ºåƒæ•¸ï¼š

python RAG_retreive.py /home/henry/automeeting/2025Feb_NSTM_meet/shorten_topicsv2/chunks_summariesv3.jsonl"""
import sys
import os
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

def load_documents(path):
    with open(path, 'r', encoding='utf-8') as f:
        return [line.strip() for line in f if line.strip()]

def search(query, docs, index, model, top_k=3):
    query_vec = model.encode([query]).astype('float32')
    distances, indices = index.search(query_vec, top_k)
    results = []
    for i, score in zip(indices[0], distances[0]):
        if i < len(docs):
            results.append((docs[i], score))
    return results

if __name__ == '__main__':
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python search_rag.py <è¼¸å…¥æª”.txt>")
        sys.exit(1)

    input_file = sys.argv[1]

    # æ§‹é€ è·¯å¾‘
    base_name = os.path.splitext(os.path.basename(input_file))[0]
    base_dir = os.path.dirname(input_file)
    output_dir = os.path.join(base_dir, f"rag_embed_{base_name}")
    index_path = os.path.join(output_dir, "faiss.index")
    doc_path = os.path.join(output_dir, "documents.txt")

    # è¼‰å…¥
    model = SentenceTransformer('all-MiniLM-L6-v2')
    index = faiss.read_index(index_path)
    docs = load_documents(doc_path)

    print(f"\nâœ… æˆåŠŸè¼‰å…¥ {len(docs)} æ®µæ–‡ä»¶ï¼Œé–‹å§‹æŸ¥è©¢ï¼è¼¸å…¥ç©ºç™½å³å¯çµæŸã€‚\n")
    
    while True:
        query = input("è«‹è¼¸å…¥æŸ¥è©¢å•é¡Œï¼š").strip()
        if not query:
            break

        results = search(query, docs, index, model)

        print(f"\nğŸ” æŸ¥è©¢ï¼šã€Œ{query}ã€")
        for i, (text, score) in enumerate(results, 1):
            print(f"\n#{i} ç›¸ä¼¼åº¦: {score:.4f}")
            print(text)