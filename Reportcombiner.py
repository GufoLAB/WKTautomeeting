import os
import re
import time
import pandas as pd
from dotenv import load_dotenv
import ollama
from tqdm import tqdm
from zhconv_rs import zhconv
from config import BACK_END_MODEL, AI_MODEL, OLLAMA_URL
from itertools import count
# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è¨­å®šåƒæ•¸
INPUT_DIR = "/home/henry/automeeting/2025Feb_NSTM_meet/shorten_topicsv2/chunks_summaries_briefv3_topic_blocks"  # TODO: æ”¹æˆä½ çš„è³‡æ–™å¤¾åç¨±
MAX_CHARS = 7000

# åˆå§‹åŒ– ollama client
client = ollama.Client(host=OLLAMA_URL)

def ai_response(messages, max_tokens=1000):
    response = client.chat(
        model=AI_MODEL,
        messages=messages
    )
    assistant_reply = response['message']['content'].strip()
    if AI_MODEL.startswith("deepseek"):
        assistant_reply = re.sub(r'<think>(.*?)</think>', '', assistant_reply, flags=re.DOTALL).strip()
    return zhconv(assistant_reply, "zh-tw")

# è™•ç†ä¸€å€‹ CSVï¼Œåˆä½µæ‰€æœ‰æ®µè½ï¼Œä¸¦ç”Ÿæˆæ‘˜è¦
def summarize_csv(filepath):
    df = pd.read_csv(filepath)

    if 'summary' not in df.columns:
        raise ValueError("CSVä¸­æ²’æœ‰'summary'æ¬„ä½")

    # åªä½¿ç”¨ summary æ¬„ä½çš„å…§å®¹ç•¶ä½œè¼¸å…¥
    all_text = '\n\n'.join(str(x) for x in df['summary'] if pd.notna(x))
    all_text = all_text[:MAX_CHARS]  # è‹¥å…§å®¹å¤ªé•·å‰‡æˆªæ–·

    messages = [{
        "role": "user",
        "content": f"ï¼š{all_text}\n\nå› ç‚ºåŸæ–‡éé•·çš„åŸå› ï¼Œä»¥ä¸Šåªæ˜¯æœƒè­°çš„ä¸€éƒ¨åˆ†ç´€éŒ„ï¼Œä½ å¿…é ˆå¯«å¥½é€™éƒ¨åˆ†çš„æœƒè­°ç´€éŒ„è€Œä¸”å¯«å¾—å¾ˆè©³ç´°ï¼Œä½†æ˜¯è®“ä»–å¯ä»¥ç„¡ç¸«æ¥ä¸Šå…¶ä»–æ®µæœƒè­°ç´€éŒ„ï¼Œæ‰€ä»¥è«‹ç”¨markdown æ ¼å¼ä¾†å¯«ä¸è¦æ¨™æ•¸å­—ï¼ä»¥ä¸Šé™„ä»¶ä¸è¨±éºæ¼ä»»ä½•èˆ‡æœƒè­°æœ‰é—œçš„ç´°ç¯€ï¼Œåªå‡†è¨±æ”¹å¯«èªå¥è®“å…¶æ›´ç¬¦åˆæœƒè­°å ±å‘Šçš„å¯«æ³•ä½†ä¸è¨±æ”¹å¯«èªæ„ å°¤å…¶æ˜¯äººäº‹æ™‚åœ°ç‰©ã€é‡‘éŒ¢ã€è²»ç”¨ç­‰éƒ½è¦å¯«å‡ºä¾†ã€‚"
    }]

    summary = ai_response(messages)
    return summary



def process_all_csvs_to_md(folder_path):
    md_lines = []
    for filename in tqdm(sorted(os.listdir(folder_path))):
        if filename.endswith(".csv"):
            filepath = os.path.join(folder_path, filename)
            try:
                summary = summarize_csv(filepath)
                md_lines.append(summary.strip() + "\n")
            except Exception as e:
                print(f"âš ï¸ è™•ç† {filename} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
    return '\n'.join(md_lines)


if __name__ == "__main__":
    start = time.time()
    merged_md = process_all_csvs_to_md(INPUT_DIR)

    # åªä¿ç•™ç¬¬ä¸€å€‹ ## æœƒè­°ç´€éŒ„æ‘˜éŒ„ï¼Œå…¶é¤˜åˆªé™¤
    counter = count(1)  # åˆå§‹åŒ–è¨ˆæ•¸å™¨å¾ 1 é–‹å§‹
    merged_md = re.sub(r'## æœƒè­°ç´€éŒ„æ‘˜éŒ„', lambda m: m.group(0) if next(counter) == 1 else '', merged_md)

    output_path = "merged_summaries.md"
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(merged_md)
    print(f"âœ… å…¨éƒ¨è™•ç†å®Œç•¢ï¼ŒèŠ±è²»æ™‚é–“ï¼š{time.time() - start:.1f} ç§’")
    print(f"ğŸ“„ å·²è¼¸å‡ºç‚º {output_path}")
