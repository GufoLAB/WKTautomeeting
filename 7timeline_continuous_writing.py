#!/usr/bin/env python3
"""
7timeline_continuous_writing.py - æŒ‰æ—¶é—´é¡ºåºç»­å†™ä¼šè®®è®°å½•

ä» CSV è¯»å– chunksï¼ŒæŒ‰ chunk_id é¡ºåºï¼ˆæ—¶é—´é¡ºåºï¼‰ä½¿ç”¨ continuous writing ç”Ÿæˆå®Œæ•´ä¼šè®®è®°å½•

ç”¨æ³•ï¼š
python 7timeline_continuous_writing.py --csv /path/to/chunks_summaries_brief.csv --output timeline_report.md
"""

import argparse
import os
import re
import time
import threading
import pandas as pd
from pathlib import Path
import ollama
from zhconv_rs import zhconv
from config import BACK_END_MODEL, AI_MODEL, OLLAMA_URL


# ==================== å·¥å…·å‡½æ•° ====================

def print_dot(stop_event):
    """æ˜¾ç¤ºè¿›åº¦ç‚¹"""
    while not stop_event.is_set():
        print('.', end='', flush=True)
        time.sleep(0.8)


def ai_response(messages, max_tokens=2000):
    """è°ƒç”¨ AI æ¨¡å‹"""
    if BACK_END_MODEL == 'openai':
        from openai import OpenAI
        client = OpenAI()
        resp = client.chat.completions.create(
            model=AI_MODEL,
            messages=messages,
            max_tokens=max_tokens
        )
        text = resp.choices[0].message.content
    else:
        client = ollama.Client(host=OLLAMA_URL)
        resp = client.chat(
            model=AI_MODEL,
            messages=messages
        )
        text = resp['message']['content']

    # ç§»é™¤ deepseek çš„ <think> æ ‡ç­¾
    if AI_MODEL.startswith('deepseek'):
        text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)

    return zhconv(text.strip(), 'zh-tw')


# ==================== Prompt è®¾è®¡ ====================

SYSTEM_PROMPT_INIT = """ä½ æ˜¯å°ˆæ¥­çš„æœƒè­°è¨˜éŒ„æ’°å¯«å°ˆå®¶ã€‚

è«‹æ ¹æ“šç¬¬ä¸€æ®µæœƒè­°æ‘˜è¦ï¼Œæ’°å¯«æœƒè­°è¨˜éŒ„çš„é–‹é ­éƒ¨åˆ†ã€‚

è¦æ±‚ï¼š
1. æå–æœƒè­°åŸºæœ¬ä¿¡æ¯ï¼ˆæ—¥æœŸã€èˆ‡æœƒè€…ã€æ™‚é•·ï¼‰
2. ä½¿ç”¨æ­£å¼çš„æœƒè­°è¨˜éŒ„æ ¼å¼
3. è©³ç´°åˆ—å‡ºé‡é»å…§å®¹
4. ä½¿ç”¨ Markdown æ ¼å¼
5. ä¸è¦æ·»åŠ åŸæ–‡æ²’æœ‰çš„å…§å®¹

ç›´æ¥è¼¸å‡ºå…§å®¹ï¼Œä¸éœ€è¦å…¶ä»–èªªæ˜ã€‚
"""


SYSTEM_PROMPT_CONTINUE = """ä½ æ˜¯å°ˆæ¥­çš„æœƒè­°è¨˜éŒ„çºŒå¯«å°ˆå®¶ã€‚

æˆ‘æœƒçµ¦ä½ ï¼š
1. å‰æ–‡çš„æœ€å¾Œ 15 è¡Œ
2. æ–°çš„æœƒè­°ç‰‡æ®µæ‘˜è¦
3. ç•¶å‰ chunk ç·¨è™Ÿ

è«‹è‡ªç„¶åœ°çºŒå¯«æœƒè­°è¨˜éŒ„ï¼š
- ä¿æŒæ‰€æœ‰é‡è¦ç´°ç¯€ï¼ˆäººäº‹æ™‚åœ°ç‰©ã€é‡‘é¡ã€æ™‚ç¨‹ç­‰ï¼‰
- è‡ªç„¶çš„æ®µè½éŠœæ¥
- å¯ä»¥é©ç•¶ä¿®æ”¹æœ€å¾Œ 15 è¡Œä½¿éŠœæ¥æ›´æµæš¢
- ä½¿ç”¨ Markdown æ ¼å¼
- ä¸è¦æ·»åŠ å¤šé¤˜çš„èªªæ˜æ–‡å­—

è«‹è¼¸å‡ºæ•´åˆå¾Œçš„æœ€çµ‚å…§å®¹ï¼ˆåŒ…å«ä¿®æ”¹å¾Œçš„å‰æ–‡æœ«æ®µ + æ–°å…§å®¹ï¼‰ã€‚
"""


# ==================== æ ¸å¿ƒåŠŸèƒ½ ====================

def initialize_report(first_chunk: dict, output_path: Path):
    """åˆå§‹åŒ–ä¼šè®®è®°å½•"""
    print(f"\nğŸ”„ åˆå§‹åŒ–æœƒè­°è¨˜éŒ„")
    print(f"  ğŸ“„ ä½¿ç”¨ç¬¬ä¸€å€‹ chunk: {first_chunk['chunk_id']}")

    user_prompt = f"""é€™æ˜¯æœƒè­°çš„ç¬¬ä¸€æ®µå…§å®¹ï¼š

{first_chunk['summary']}

è«‹æ’°å¯«æœƒè­°è¨˜éŒ„çš„é–‹é ­éƒ¨åˆ†ã€‚"""

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT_INIT},
        {"role": "user", "content": user_prompt}
    ]

    # AI å¤„ç†
    print(f"  ğŸ¤– AI æ­£åœ¨è™•ç†", end='')
    stop_event = threading.Event()
    dot_thread = threading.Thread(target=print_dot, args=(stop_event,))
    dot_thread.start()

    try:
        initial_content = ai_response(messages, max_tokens=2000)
    finally:
        stop_event.set()
        dot_thread.join()

    print(f" âœ…")

    # æ·»åŠ æŠ¥å‘Šå¤´éƒ¨
    final_content = f"""# æœƒè­°è¨˜éŒ„ï¼ˆæŒ‰æ™‚é–“é †åºï¼‰

---

{initial_content}
"""

    # å†™å…¥æ–‡ä»¶
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(final_content)

    print(f"  ğŸ’¾ åˆå§‹è¨˜éŒ„å·²å»ºç«‹")


def integrate_next_chunk(output_path: Path, chunk: dict, chunk_index: int, total_chunks: int):
    """æ•´åˆä¸‹ä¸€ä¸ª chunk"""
    print(f"\nğŸ”„ æ•´åˆ Chunk {chunk_index}/{total_chunks}")
    print(f"  ğŸ“„ {chunk['chunk_id']}")

    # è¯»å–å½“å‰æŠ¥å‘Šçš„æœ€å 15 è¡Œ
    with open(output_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    last_15_lines = ''.join(lines[-15:] if len(lines) >= 15 else lines)

    # æ£€æŸ¥å­—æ•°
    summary_text = chunk['summary']
    total_chars = len(last_15_lines) + len(summary_text)
    print(f"  ğŸ“Š è¼¸å…¥å­—æ•¸ï¼šå‰æ–‡ {len(last_15_lines)} + æ–°å…§å®¹ {len(summary_text)} = {total_chars} å­—")

    if total_chars > 4000:
        print(f"  âš ï¸  è­¦å‘Šï¼šç¸½å­—æ•¸è¶…é 4000ï¼Œå¯èƒ½å½±éŸ¿è™•ç†æ•ˆæœ")

    # æ„å»º prompt
    user_prompt = f"""å‰æ–‡æœ€å¾Œ 15 è¡Œï¼š

{last_15_lines}

---

æ–°çš„æœƒè­°ç‰‡æ®µï¼ˆchunk {chunk_index}ï¼‰ï¼š

{summary_text}

---

è«‹è‡ªç„¶åœ°å°‡æ–°å…§å®¹æ¥çºŒåˆ°å‰æ–‡ï¼Œè¼¸å‡ºå®Œæ•´çš„æœ€çµ‚å…§å®¹ã€‚"""

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT_CONTINUE},
        {"role": "user", "content": user_prompt}
    ]

    # AI å¤„ç†
    print(f"  ğŸ¤– AI æ­£åœ¨æ•´åˆ", end='')
    stop_event = threading.Event()
    dot_thread = threading.Thread(target=print_dot, args=(stop_event,))
    dot_thread.start()

    try:
        merged_content = ai_response(messages, max_tokens=2000)
    finally:
        stop_event.set()
        dot_thread.join()

    print(f" âœ…")

    # æ›´æ–°æ–‡ä»¶ï¼šæ›¿æ¢æœ€å 15 è¡Œ
    if len(lines) >= 15:
        new_lines = lines[:-15] + [merged_content + '\n']
    else:
        new_lines = [merged_content + '\n']

    with open(output_path, 'w', encoding='utf-8') as f:
        f.writelines(new_lines)

    print(f"  ğŸ’¾ å·²æ›´æ–°è¨˜éŒ„")

    # æ¯ 10 ä¸ª chunks ä¿å­˜ä¸€æ¬¡å¤‡ä»½
    if chunk_index % 10 == 0:
        backup_path = output_path.parent / f"{output_path.stem}_backup_{chunk_index}.md"
        with open(backup_path, 'w', encoding='utf-8') as f:
            f.writelines(new_lines)
        print(f"  ğŸ’¾ å·²ä¿å­˜å‚™ä»½ï¼š{backup_path.name}")


def timeline_continuous_write(csv_file: Path, output_path: Path):
    """ä¸»æµç¨‹ï¼šæŒ‰æ—¶é—´é¡ºåºç»­å†™"""

    print("="*60)
    print("ğŸš€ é–‹å§‹æŒ‰æ™‚é–“é †åºçºŒå¯«æœƒè­°è¨˜éŒ„")
    print("="*60)

    # è¯»å– CSV
    df = pd.read_csv(csv_file)
    total_chunks = len(df)

    print(f"ğŸ“Š ç¸½å…± {total_chunks} å€‹ chunks")
    print(f"ğŸ“„ è¼¸å‡ºï¼š{output_path}")

    # æ­¥éª¤ 1ï¼šåˆå§‹åŒ–
    first_chunk = df.iloc[0].to_dict()
    initialize_report(first_chunk, output_path)

    # æ­¥éª¤ 2ï¼šé€ä¸ªæ•´åˆ
    for i in range(1, total_chunks):
        chunk = df.iloc[i].to_dict()
        integrate_next_chunk(output_path, chunk, i+1, total_chunks)

    print("\n" + "="*60)
    print("âœ… æ™‚é–“ç·šæœƒè­°è¨˜éŒ„ç”Ÿæˆå®Œæˆï¼")
    print("="*60)

    # æ˜¾ç¤ºç»Ÿè®¡
    with open(output_path, 'r', encoding='utf-8') as f:
        final_lines = f.readlines()

    file_size = output_path.stat().st_size / 1024
    print(f"ğŸ“„ æœ€çµ‚å ±å‘Šï¼š{output_path}")
    print(f"ğŸ“Š ç¸½è¡Œæ•¸ï¼š{len(final_lines)}")
    print(f"ğŸ“¦ æª”æ¡ˆå¤§å°ï¼š{file_size:.1f} KB")


# ==================== ä¸»ç¨‹åº ====================

def main():
    parser = argparse.ArgumentParser(
        description='æŒ‰æ™‚é–“é †åºçºŒå¯«æœƒè­°è¨˜éŒ„'
    )

    parser.add_argument('--csv', required=True,
                       help='chunks_summaries_brief.csv æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', default='timeline_report.md',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    start_time = time.time()

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    csv_file = Path(args.csv)
    if not csv_file.exists():
        print(f"âŒ CSV æ–‡ä»¶ä¸å­˜åœ¨ï¼š{csv_file}")
        return

    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if args.output == 'timeline_report.md':
        output_path = csv_file.parent.parent / args.output
    else:
        output_path = Path(args.output)

    # æ‰§è¡Œç»­å†™
    timeline_continuous_write(csv_file, output_path)

    # æ€»ç»“
    elapsed = time.time() - start_time
    print(f"\nâ±ï¸  ç¸½è€—æ™‚ï¼š{elapsed:.1f} ç§’ ({elapsed/60:.1f} åˆ†é˜)")


if __name__ == '__main__':
    main()
